\documentclass[../statistical_inference.tex]{subfiles}
\begin{document}
\section{Aula 15 - 04 de Fevereiro, 2025}
\subsection{Motivações}
\begin{itemize}
	\item A segurança de processos de aleatorização.
\end{itemize}
\subsection{Processos de Aleatorização Seguros}
Finalizaremos, hoje, nossos estudos relacionados ao tópico de randomização; já vimos como gregos e hebraicos achavam do assunto, e hoje começaremos mostrando o que os romanos pensavam.

O império Romano é conhecido por sua capacidade de governar, deixando um grande legado cultural em sua língua; nessa linha, os romanos tinham um ditado, de que as coisas não podiam apenas ser feitas corretamente, mas precisam também parecer terem sido feitas corretamente:
\begin{quote}
	``\textit{Meos tam suspicione quam crimine iudico carere oportere}'' -- Julius Caesar (62 BC), em Suetonius (119CE, Sec.I.74.2).
\end{quote}

Para ele, as pessoas em volta de si não podiam apenas não portar um crime, mas também não poderiam sequer ser suspeitos de portar um crime. Nesse tipo de raciocínio, para o contexto de randomização, concluímos que eles não precisam apenas ter as propriedades matemáticas desejáveis, mas também deveriam ser inteligíveis e auditáveis, diminuindo as suspeitas nele.

Para que não haja suspeita, é preciso convencer as pessoas do processo, e para isso existem algumas formas: uma delas é a \textbf{segurança por obscuridade}, consistindo em esconder o processo, como, onde e por que ele foi feito, evitando que as pessoas externas afetem o processo; a outra, é a \textbf{segurança por desenho}, segundo os princípios de Kerckhoffs, fazendo com que ele seja seguro por sua própria natureza, que tem algumas vantagens, tal qual a simplicidade de implementação, facilidade de uso, traçabilidade, flexibilidade, eficiente e verificavelmente seguro, fazendo com que uma dada informação não seja decifrável sem a permissão de quem a quer transmitir.
Esses processos, inclusive, seriam muito vantajosos para tribunais caso fossem implementados, afinal não dependeriam de argumentos de autoridade e poderia ajudar a população a estar mais em segurança com os processos pelos quais podem passar, sendo isso muito vantajoso para uma sociedade democrática!

O que podemos, então, aprender a partir de uma análise \textit{post hoc} dos processos de distribuição utilizados nos tribunais? Será que analisando essas massas de dados, seria possível discernir algum viés? A pergunta em si tem sua importância, afinal uma boa parte dos casos que chegam ao supremo têm importância política, e sempre que um caso com interesse político chegue a algum juiz ou relator de processo que contém alguma influência política mais forte, há um desfavorecimento de um dos lados.
Conforme os estudos de Diego Marcondes, Cláudia Peixoto e Júlio Stern, as conclusões obtidas são parecidas às que são possíveis com análises estatísticas, sendo ela que, apesar de alguns desvios até podem ser importantes, está tudo certo na média, mas não é possível afirmar nada sobre casos particulares, afinal os resultados sempre se referem a um grande número de dados ou observações... Porém, não era isso que queriam, mas sim a capacidade de ver se cada processo foi feito corretamente!

O que fizeram, então, foi utilizar uma randomização de \textit{blockchain} com \textit{bitstreams} de alta entropia, pois não seria possível com análises estatísticas \textit{post-hoc}, só sendo possível com um processo de randomização que tenha todas as características de auditabilidade e traçabilidade necessárias para dar tal segurança.
Por isso, publicaram um artigo que mostrava como fazer isso, e chegaram à conclusão desejada utilizando o sistema já existente citado há pouco com blockchains para criptomoedas: sempre que uma compra com criptomoedas é feita, o comprador dá o nome da carteira, da carteira de quem vai receber, o valor e um pequeno campo de texto para adicionar um comentário!
Toda essa informação vai para um cartório público, que se chama blockchain do bitcoin, e tudo que ocorre nele fica à disposição do público, é incorruptível (não pode ser alterada um vez feita) e é indelével (não é possível deletar uma informação que esteja lá), ou seja, além da garantia de que a informação não pode ser adulterada, é muito importante que ela não possa ser apagada, pois daria brecha para a re-randomização, garantindo o caso que não quer até que saia o caso desejado.

Fica claro de entender por que todas as características acima são desejáveis em um processo, também sendo possível entender as vantagens de processos aleatórios seguros por desenho! A solução dada por eles é, então, uma forma muito boa de manter o que os juízes queriam, até porque foi feita com código de fonte aberta.
Infelizmente, essa solução não foi adotada, afinal haviam muitas objeções, tal como sistemas sendo desenvolvidos internamente por pessoas que supostamente deram uma solução ótima, mas que não podiam ser reveladas -- ou seja, segurança por obscuridade, cujos problemas foram muito bem pontuados pelo matemático Courtois em 2009:
\begin{quote}
	``We must realize that the secrecy of a product specification poses a threat of a very large scale electronic subversion. We need to have the courage to examine these questions and stop pretending that research in security is about discovering vulnerabilities that are always not intentional... Developers are also potential attackers for all such systems and trade/ industrial secrets should always be regarded as, potentially, a very major security breach.''
\end{quote}
Ou seja, muitas vezes supomos que o agente que desenvolveu o sistema e o atacante são entidades distintas, mas em diversos casos importantes que tiveram sistemas desse tipo quebrados, houve a captação de uma pessoa interna para dar informação privilegiada, então essa própria hipótese de separabilidade entre desenvolvedor e atacante é falha, fazendo com que a segurança por obscuridade caia por terra -- a moral é que esse não é o caminho, pois ele é vulnerável, a versão por desenho é bem mais segura.

Uma razão ainda mais forte para não usar a segurança por obscuridade é uma sociológica, e aqui vale a pena voltar a falar do Luhmann e seu referencial teórico da teoria social do direito: segundo ele, a função do direito não é apenas fazer julgamentos, mas há um papel de ainda mais alto nível que é a generalização congruente de expectativas normativas comportamentais, ou seja, o estímulo de adoção e cumprimento de normas comportamentais que a sociedade considera boas e, por outro lado, coibir comportamentos que ela considere ruim.
Para isso funcionar, o sistema de direitos deve justamente convencer as pessoas a seguirem essas normas, que pode ser feito pelo medo, utilizando consequências terríveis aos desvios, ou utilizando o engajamento da sociedade a esses processos, afinal a sociedade como um todo precisa aceitar e se convencer de que elas são desejáveis, podendo reformá-las caso não sejam, e que as instituições e tribunais do sistema democrático são honestas; apenas assim, a generalização congruente de expectativas normativas podem ser obtidas para ela! Tornar todos os processos transparentes, auditáveis e verificavelmente honestos é parte desse esforço.

Se fica uma crítica à solução dos autores que tem algum mérito é o uso do blockchain do bitcoin, afinal não ficaria bem pro tribunal brasileiro usar o sistema de uma criptomoedas que nem sequer é brasileira... Conseguiram fazer um sistema alternativo! Mas, ao ser oferecida, ela foi novamente negada pelos tribunais...

\end{document}
