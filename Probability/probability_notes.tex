\documentclass{article}
 \usepackage{amsmath}
 \usepackage{xcolor}
 \usepackage{amsthm}
 \usepackage{amssymb}
 \usepackage{pgfplots}
 \usepackage[utf8]{inputenc}
 \usepackage{amsfonts}
 \usepackage[margin=2.5cm]{geometry}
 \usepackage{graphicx}
 \usepackage[export]{adjustbox}
 \usepackage{fancyhdr}
 \usepackage[portuguese]{babel}
 \usepackage{hyperref}
 \usepackage{lastpage}
 \usepackage{mathtools}
 \usepackage[light, math]{iwona}
 \usepackage[T1]{fontenc}
 \setcounter{section}{-1}

 \pagestyle{fancy}
 \fancyhf{}

 \pgfplotsset{compat = 1.18}

 \hypersetup{
     colorlinks,
     citecolor=black,
     filecolor=black,
     linkcolor=black,
     urlcolor=black
 }
 \newtheorem*{def*}{\underline{Defini\c c\~ao}}
 \newtheorem*{theorem*}{\underline{Teorema}}
 \newtheorem*{lemma*}{\underline{Lema}}
 \newtheorem*{prop*}{\underline{Proposi\c c\~ao}}
 \newtheorem{example}{\underline{Exemplo}}
 \newtheorem*{proof*}{\underline{Prova}}
 \renewcommand\qedsymbol{$\blacksquare$}

 \rfoot{P\'agina \thepage \hspace{1pt} de \pageref{LastPage}}

 \begin{document}
 \begin{figure}[ht]
  \minipage{0.76\textwidth}
    \includegraphics[width=4cm]{icmc.png}
    \hspace{7cm}
    \includegraphics[height=4.9cm,width=4cm]{brasao_usp_cor.jpg}
  \endminipage  
\end{figure}

\begin{center}
  \vspace{1cm}
  \LARGE
  UNIVERSIDADE DE S\~AO PAULO

  \vspace{1.3cm}
  \LARGE
  INSTITUTO DE CI\^ENCIAS MATEM\'ATICAS E COMPUTACIONAIS - ICMC

  \vspace{1.7cm}
  \Large
  \textbf{Introdução à Probabilidade}

  \vspace{1.3cm}
  \large
  \textbf{Renan Wenzel - 11169472}

  \vspace{1.3cm}
  \large
  \textbf{Professor: Oilson Alberto Gonzatto Junior}

  \textbf{E-mail: oilson.agjr@icmc.usp.br}

  \vspace{5cm}
  \today
\end{center}

 \newpage

 \tableofcontents

 \newpage

\section{Informações (Possivelmente) Úteis}
\subsection*{Monitoria}
\begin{itemize}
  \item[Monitora:] Patrícia Stülp
  \item[E-mail:] \textit{patriciastulp2@gmail.com}
\end{itemize}
\subsection*{Datas das Provas}
  \subsubsection*{Mini provas}
 \begin{itemize}
   \item[i)] 29/08/2023;
   \item[ii)] 12/09/2023; 26/09/2023;
   \item[iii)] 10/10/2023; 24/10/2023;
   \item[iv)] 07/11/2023; 21/11/2023;
   \item[v)] 05/12/2023
 \end{itemize}
 \subsubsection*{(Talvez) P3}
  Pode não ocorrer, mas, a depender dos resultados das mini-provas, será dia 12/12/2023.
\subsection*{Bibliografia}
\begin{itemize}
  \item[Principal:] MEYER, P. L. ``Probabilidade: Aplicações à Estatística'', 2a edição, LTC, Rio de Janeiro, 2009.
  \item[Complementar:] ROSS, S. A. ``First Course in Probability", 8th edition, Pearson, 2010.
\end{itemize}

 \newpage
\section{Aula 01 - 22/08/2023}
\subsection{Motivações}
\begin{itemize}
  \item O que é aleatoriedade e probabilidade?
  \item Conceitos Fundamentais;
\end{itemize}
\subsection{Aleatoriedade, probabilidade e conceitos fundamentais}
  A probabilidade está nos conceitos bases da ciência atual, sendo resultado de uma revolução na ciência há um século atrás.
A noção de aleatoriedade, no entanto, é muito mais difícil de obter uma resposta.

  Começamos com um experimento E - um mecanismo gerado. Dele, obtemos um resultado \(\omega \). A estes resultados,
associamos um conjunto, chamado de evento \(A = \{\omega_{1}, \cdots, \omega_{k}\}\). Com estas ideias, associa-se um valor
a um evento, chamado probabilidade \(\mathbb{P}(A).\) Vamos compreender estas ideias mais a fundo.

\subsubsection{Experimentos}
  Experimentos podem ser distinguidos em alguns tipos. O primeiro deles é o determinístico. Nele,
o resultado obtido é determinado pelas condições sob as quais o experimento foi executado. A outra forma 
é conhecida como experimento aleatório, que engloba experimentos cujos resultados não sabemos \textit{a priori}, isto é,
 ainda que as condições iniciais sejam fixas, os resultados não podem ser previstos. Eles possuem as seguintes características:
 \begin{itemize}
   \item[a)] Mesmo repetindo várias vezes com as mesmas condições iniciais, o resultado pode mudar;
   \item[b)] Apesar da falta de exatidão, é possível descrever o conjunto de todos os resultados possíveis;
   \item[c)] Há uma regularidade nos resultados após ele ser repetido muitas vezes, permitindo uma modelagem matemática dele.
\subsubsection{Espaço Amostral}
  O espaço amostral denota todos os resultados que podem ocorrer ao realizar um experimento aleatório.
  
  \textbf{Observação:} O mecanismo gerador está limitado a um determinado conjunto de possibilidades de saídas.
 \end{itemize}
\begin{example}
  Se considerarmos características sócio demográficas de um grupo de pessoas, poderíamos ter
 \begin{itemize}
   \item[Sexo:)] \{Masculino, Feminino, Intersexo\}
   \item[Idade:)] \{0, 1, 2, ...\}
   \item[Estado civil:)] \{Solteiro, Casado, Viúvo, outros.\}
   \item[Renda familiar:)] \(\{x: x\in \mathbb{R}^{+}\}\)
 \end{itemize}
\end{example}
\begin{example}
  Dados os experimentos aleatórios, quais são os espaços amostrais?
 \begin{itemize}
   \item[\(E_{1}\))] Lançar uma moeda 2 vezes e observar as faces obtidas; \(\Omega =\{(C, C), (C, K), (K, C), (K, K)\}\)
   \item[\(E_{2}\))] Retirar uma carta de um barulho comum e observar o naipe; \(\Omega\)=\{``ouros'', ``copas'', ``paus'', ``espadas''\}
   \item[\(E_{3}\))] Duração de lâmpadas, deixando-as acesas até que queimem; \(\Omega = \{t: t\geq 0\}\)
   \item[\(E_{4}\))] Número de mensagens por dia entre uma empresa e um determinado cliente. \(\Omega = \{t: t\geq 0\}\)
 \end{itemize}
\end{example}
\subsubsection{Evento}
  Um evento representa qualquer dúvida que possa surgir sobre o resultado de um experimento. Em particular, podem ser visualizados como subconjuntos do espaço amostral. Com isso,
o próprio amostral é um evento, chamado evento certo, assim como o vazio é um evento, dito evento impossível.
\begin{example}
  Considere o resultado obtido com o lançamento de um dado de seis faces, equilibrado. O espaço amostral é \(\{1, 2, 3, 4, 5, 6\}\). Descrevamos os seguintes eventos:
 \begin{itemize}
   \item[1)] A = ``ocorrência do número 3'' = \{3\};
   \item[2)] B = ``sair a face de número 7'' = \(\emptyset\);
   \item[3)] C = ``sair um número menor ou igual a 6'' = \(\Omega \).
 \end{itemize}
\end{example}
\begin{example}
  Podemos considerar experimentos cujos resultados podem ser vetores. A exemplo, o preço de fechamento de determinadas
ações em uma data específica, como \(\omega = \)(PETR4, ITUB4, ..., AZUL4). Nesse contexto, um evento possível poderia ser 
a situação em que a média desse vetor de preços seja maior do que a média do dia anterior.
\end{example}
\subsubsection{Operações com Eventos}
  Veja que um experimento aleatório pode ser tão complicado quanto necessário. Buscamos, porém, buscar simplificações confiáveis para descrever com probabilidades
estes comportamentos, ou seja, estabelecer as propriedades básicas da função de probabilidade. Antes de mais nada, porém, torna-se necessário
saber como operar os eventos. 

  Como eventos são subconjuntos do espaço amostral, a operação entre eles é dada por meio das operações entre conjuntos - 
união, interseção, complemento, etc. Nesta lógica, compreendemos como
\begin{itemize}
  \item[] União de eventos - a capacidade do evento A OU do evento B ocorram;
  \item[] Interseção de eventos - a capacidade do evento A E do evento B ocorrerem simultaneamente.
  \item[] Complementar - a capacidade do evento A não acontecer
  \item[] Eventos mutuamente exclusivos - A e B não ocorrem simultaneamente, isto é, \(A\cap B = \emptyset\)
\end{itemize}
\begin{example}
  Um número entre 1 e 10 é selecionado ao acado. Considere A como o evento em que o número selecionado é múltiplo de 3 e B o conjunto em que o número selecionado é par. Então, 
 \(\Omega = \{1, 2, \cdots, 10\}, A = \{3, 6, 9\}, B = \{2, 4, 6, 8, 10\}\). O evento que ocorre nos dois é \(A\cap B=\{6\}\). O evento representando que o número seja um múltiplo de 3 ou
 um número par é \(A\cup B = \{2, 3, 4, 6, 8, 9, 10\}\). Alguns outros são: \(A\cap B^{c} = \{3, 9\}, A^{c}\cap B = \{2, 4, 8, 10\}.\)
\end{example}
\newpage
\section{Aula 02 - 24/08/2023}
\subsection{Motivações}
\begin{itemize}
  \item As definições de probabilidade;
  \item A probabilidade segundo Kolmogorov.
\end{itemize}
\subsection{Conceitos}
\paragraph{}As ideias desenvolvidas até aqui são as que Laplace desenvolveu, contendo toda a parte do cálculo
de probabilidade por meio da contagem de casos favoráveis e dos possíveis. No entanto, foram desenvolvidas outras
abordagens para lidar com as limitações da dependência na uniformidade das saídas, no número finito de resultados possíveis, etc.
A definição clássica de probabilidade é a razão entre o número de casos favoráveis e o de possíveis, ou seja, 
\begin{def*}
  Seja o evento A, associado a um espaço amostral finito e equiprovável, \(\Omega \). Definimos a probabilidade de ocorrência do evento A por: 
    \[
      \mathbb{P}(A) = \frac{\#(A)}{\#(\Omega )}.\quad \square
    \]
\end{def*}
  Richard von Mises buscou enxergar a probabilidade como algo que pode ser definido apenas para um gerador aleatório capaz de produzir uma sequência infinita de resultados.
A probabilidade, aqui, será a frequência limite do resultado nessa sequência. Ele baseou isso na ideia de que a aleatoriedade é um processo que produz resultados imprevisíveis
e não claramente determinados.
\begin{def*}
  Seja \(n_{A}\) o número de vezes que o evento A ocorre em n repetições independente de um mesmo experimento. Então, 
    \[
      \mathbb{P}(A) = \lim_{n\to \infty}\frac{n_{A}}{n},
    \]
    desde que o limite exista. \(\square\)
\end{def*}
 Essa definição mostrou-se importante até durante a contemporaneidade. No entanto, não é muito prático para fazer contas e encontrar probabilidades, 
sua força está em exibir a noção que a aplicabilidade traz. Além disso, ela funciona como uma ponte entre a primeira definição e a próxima que será vista.
Outro problema com essa é que, quando quantidades enormes de saídas surgem, torna-se impossível de usá-lo, pois não dá para saber o total de possibilidades.
  
  Assim, Kolmogorov estende a definição de probabilidade para espaços mais gerais, conhecido como a pessoa que formalizou a teoria da probabilidade. A ideia dele permite que
propostas mais flexíveis de probabilidades sejam usadas, saindo do limite de contabilidade finita e equiprovável da ideia de Laplace.
\begin{def*}
  Seja E um experimento aleatório e \(\Omega \) o espaço amostral associado. A cada evento A associamos um número real
 \(\mathbb{P}(A)\), denominado probabilidade de A, que satisfaz 
\begin{itemize}
  \item[P1)] \(\mathbb{P}(\Omega )=1;\)
    \item[P2)] \(0\leq \mathbb{P}(A)\leq 1,\) para todo A decorrente de \(\Omega \);
      \item[P3)] Se A e B forem eventos mutuamente exclusivos, então 
        \[
          \mathbb{P}(A\cup B) = \mathbb{P}(A) + \mathbb{P}(B);
        \]
      \item[P4)] Para qualquer sequência de eventos disjuntos dois-a-dois, \(A_{1}, A_{2}, \cdots, A_{n}\), tem-se 
        \[
          \mathbb{P}\biggl(\bigcup_{i=1}^{n}A_{i}\biggr) = \sum\limits_{i=1}^{n}\mathbb{P}(A_{i}).\quad \square
        \]
\end{itemize}
\end{def*}
  Seguem algumas propriedades:
 \begin{theorem*}
   Se \(\emptyset\) é um evento impossível, então \(\mathbb{P}(\emptyset) = 0.\)
 \end{theorem*}
 \begin{theorem*}
  Se \(A^{c}\) for o complementar de A, então \(\mathbb{P}(A^{c}) = 1 - \mathbb{P}(A).\)
 \end{theorem*}
\begin{theorem*}
  Se A e B são dois eventos quaisquer de \(\Omega \), então 
    \[
      \mathbb{P}(A\cup B) = \mathbb{P}(A) + \mathbb{P}(B) - \mathbb{P}(A\cap B).
    \]
\end{theorem*}
\begin{theorem*}
  Se \(A_{1}, A_{2}, \cdots, A_{i}\) são eventos dois-a-dois disjuntos, então 
  \begin{align*}
    \mathbb{P}(A_{1}\cup \cdots\cup A_{i}) &= \sum\limits_{i=1}^{n}\mathbb{P}(A_{i}) - \sum\limits_{i < j}^{n} \mathbb{P}(A_{i}\cap A_{j}) + \sum\limits_{i < j < r}^{n} \mathbb{P}(A_{i}\cap A_{j}\cap A_{r}) + \cdots\\
                                           &\cdots + (-1)^{n-1}\mathbb{P}(A_{1}\cap \cdots A_{n})
  \end{align*}
\end{theorem*}
\begin{example}
  Um lote é formado por 10 peças boas, 4 com defeitos menores e 2 com defeitos graves. Uma peça é escolhida ao acaso. Calcule a probabilidade de que 
 \begin{itemize}
   \item[a)] A peça não tenha defeito grave;
   \item[b)] A peça não tenha defeito;
   \item[c)] A peça seja boa ou tenha defeito grave.
 \end{itemize}
  a) Considerando A o conjunto de peças boas, B o de peças levemente defeituosas e C o de peças gravemente defeituosas, esses conjuntos são dois-a-dois disjuntos. Assim, 
    \[
      \mathbb{P}(C^{c}) = 1 - \mathbb{P}(C) = 1 - \frac{2}{16} = \frac{7}{8}.
    \]
    
  b) Com a notação anterior, 
    \[
      \mathbb{P}((B\cup C)^{c}) = \mathbb{P}(B^{c}\cap C^{c}) = \mathbb{P}(B^{c}) + \mathbb{P}(C^{c}) - \mathbb{P}(C^{c}\cup B^{c}) = \mathbb{P}(A) = \frac{10}{16} = \frac{5}{8}.
    \]

  c) Novamente, mantendo a anotação, 
    \[
      \mathbb{P}(A\cup C) = \mathbb{P}(A) + \mathbb{P}(C) = \frac{10}{16} + \frac{2}{16} = \frac{12}{16} = \frac{3}{4}.
    \]
\end{example}
\newpage

\section{Aula 03 - 31/08/2023}
\subsection{Motivações}
\begin{itemize}
  \item Probabilidade Condicional;
  \item Dependência de Eventos.
\end{itemize}
\subsection{A Probabilidade Condicional}
\begin{def*}
  Sejam dois eventos A e B associados ao mesmo espaço amostral \(\Omega \). A probabilidade condicional de A 
dado que ocorreu B é representada por \(\mathbb{P}(A|B\) e dada por 
  \[
    \mathbb{P}(A|B) = \frac{\mathbb{P}(A\cap B)}{\mathbb{P}(B)},\quad \mathbb{P}(B) > 0\quad \square.
  \]
\end{def*}
  Em particular, seguem duas representações para a probabilidade de dois eventos ocorrerem simultaneamente, sendo elas
  \begin{align*}
    &\mathbb{P}(A|B) = \frac{\mathbb{P}(A\cap B)}{\mathbb{P}(B)} \Rightarrow \mathbb{P}(A\cap B) = \mathbb{P}(A|B)\mathbb{P}(B)\\
    &\mathbb{P}(B|A) = \frac{\mathbb{P}(A\cap B)}{\mathbb{P}(A)} \Rightarrow \mathbb{P}(A\cap B) = \mathbb{P}(B|A)\mathbb{P}(A)\\
  \end{align*}
  \begin{example}
    Um dado de seis faces, equilibrado, é lançado e o número voltado para cima é obsecrado.
    \begin{itemize}
      \item[(a)] Se o resultado obtido for par, qual a probabilidade dele ser maior ou igual a 5?
      
    \item[(b)] Se o resultado obtido for maior ou igual a 5, qual a probabilidade dele ser par?
\end{itemize}

    Para o item a, o espaço amostral é \(\Omega = \{1, 2, 3, 4, 5, 6\}\). Considere os eventos
    A como o resultado de ser par e B o resultado obtido sendo maior ou igual a 5. Então, 
      \[
        \mathbb{P}(B|A) = \frac{\mathbb{P}(A\cap B)}{\mathbb{P}(A)} = \frac{\mathbb{P}(\{6\})}{\mathbb{P}(\{2, 4, 6\})} = \frac{1}{3};
      \]

      Para o item b, temos 
        \[
          \mathbb{P}(A|B) = \frac{\mathbb{P}(A\cap B)}{\mathbb{P}(B)} = \frac{\mathbb{P}(\{6\})}{\mathbb{P}(\{5, 6\})} = \frac{\frac{1}{6}}{\frac{2}{6}} = \frac{1}{2}.
        \]
  \end{example}
 \begin{def*}
   Os eventos A e B são independentes se a informação da ocorrência de B não altera a probabilidade atribuída ao evento A, isto é, 
     \[
       \mathbb{P}(A|B) = \mathbb{P}(A),
     \]
    ou, equivalentemente, 
    \[
      \mathbb{P}(A\cap B) = \mathbb{P}(A)\mathbb{P}(B).\quad\square
    \]
 \end{def*}
\begin{example}
  Uma moeda é viciada, de modo que a chance de sair cara é o dobro da de sair coroa.
  \begin{itemize}
    \item[(a)] Dê o espaço amostral

  \item[(b)] Calcule a probabilidade de ocorrer cara no lançamento desta moeda.
\end{itemize}

  (a) O espaço amostral desse evento é \(\Omega = \{\text{Cara, Coroa}\}\). Seja A o evento que cai cara e B o que cai coroa.

  (b) Sabemos que \(\mathbb{P}(A) + \mathbb{P}(B) = 1\) e que \(\mathbb{P}(A) = 2 \mathbb{P}(B)\), ou seja, 
    \[
      \mathbb{P}(A) + \frac{\mathbb{P}(A)}{2} = 1 \Rightarrow \mathbb{P}(A) = \frac{2}{3}.
    \]
\end{example}
\begin{example}
  Duas lâmpadas queimadas foram acidentalmente misturadas com seis boas. Se vamos testar as lâmpadas, uma por uma, até
encontrar duas defeituosas, qual é a probabilidade de que a última defeituosa seja encontrada no quarto teste?

  Estamos interessados em calcular a probabilidade do seguinte evento:
 \begin{align*}
   (\overline{D_{1}}\cap \overline{D_{2}}\cap D_{3}\cap D_{4})\cup(\overline{D_{1}}\cap D_{2}\cap \overline{D_{3}}\cap D_{4})\cup(D_{1}\cap \overline{D_{2}}\cap \overline{D_{3}}\cap D_{4})\\
   &\Rightarrow \mathbb{P}(\overline{D_{1}}\cap \overline{D_{2}}\cap D_{3}\cap D_{4})\cup(\overline{D_{1}}\cap D_{2}\cap \overline{D_{3}}\cap D_{4})\cup(D_{1}\cap \overline{D_{2}}\cap \overline{D_{3}}\cap D_{4})\\
   &= \mathbb{P}(\overline{D_{1}}\cap \overline{D_{2}}\cap D_{3}\cap D_{4}) + \mathbb{P}(\overline{D_{1}}\cap D_{2}\cap \overline{D_{3}}\cap D_{4}) + \mathbb{P}(D_{1}\cap \overline{D_{2}}\cap \overline{D_{3}}\cap D_{4}).
 \end{align*}
  Após manipulações algébricas e contas, chegamos em 
    \[
      \frac{1}{28} + \frac{1}{28} + \frac{1}{28} = \frac{3}{28}\approx 0,1071.
    \]
\end{example}
\begin{def*}
  Dizemos que \(A_{1}, A_{2}, \cdots, A_{n}\) formam uma partição de \(\Omega \) se eles são dois-a-dois disjuntos e a sua união é \(\Omega.\quad\square \)
\end{def*}
\begin{theorem*}
  Suponha que os eventos \(A_{1}, A_{2}, \cdots, A_{n}\) formam uma partição de \(\Omega \) e que todos têm probabilidade positiva. Então, para qualquer evento B, 
    \[
      \mathbb{P}(B) = \sum\limits_{i=1}^{n}\mathbb{P}(B|A_{i})\mathbb{P}(A_{i})
    \]
\end{theorem*}
\begin{example}
  Uma companhia produz circuitos integrados em três fábricas, sendo elas A, B e C. A fábrica A produz 40\% deles, e as outras produzem 30\% cada. As probabilidades de que um circuito integrado produzido por essas fábricas não funcione são 
 \(0,01; 0,04; 0,03\) respectivamente. Escolhido um circuito da produção conjunta das três fábricas, qual a probabilidade dele não funcionar? 
  
  Sendo D o evento em que o circuito é defeituoso e A, B, C os eventos de cada fábrica, sabemos que 
    \[
      \mathbb{P}(A) = 0,40,\quad \mathbb{P}(B) = 0,30,\quad \mathbb{P}(C) = 0,30.
    \]
    Além disso, sabemos que 
    \[
      \mathbb{P}(D|A) = 0,02,\quad \mathbb{P}(D|B) = 0,04,\quad \& \mathbb{P}(D|C) = 0,03
    \]
    Segue do teorema que 
      \[
        \mathbb{P}(D) = \sum\limits_{i=1}^{n}\mathbb{P}(D|A_{i})\mathbb{P}(A_{i}) = 0,025.
      \]

    Determine a probabilidade do defeituoso ter sido produzido pela empresa A. 
      \[
        \mathbb{P}(A|D) = \frac{\mathbb{P}(A\cap D)}{\mathbb{P}(D)} = \frac{\mathbb{P}(D|A)\mathbb{P}(A)}{\mathbb{P}(D)} = \frac{0,01\times 0,4}{0,025} = \frac{0,004}{0,025} = 0,16.
      \]
\end{example}
\newpage

\section{Aula 04 - 07/09/2023}
\subsection{Motivações}
\begin{itemize}
  \item Noções de Contagens e resultados iniciais;
  \item Princípio Fundamental da Contagem.
\end{itemize}

\newpage

\section{Aula 05 - 19/09/2023}
\subsection{Motivações}
\begin{itemize}
  \item Variáveis Aleatórias;
  \item Distribuições discretas;
  \item Massa de probabilidade.
\end{itemize}
\subsection{Observação}
  A aula 04 foi, na verdade, uma aula sobre contabilidade, que irei adicionar futuramente, pois não consegui copiar ela na hora.
\subsection{Variáveis aleatórias}
  Na descrição de um experimento aleatório, é conveniente descrever numericamente os resultados.
Vimos, ao longo do curso, exemplos de experimentos que já vinham atrelados a números - o tempo de duração
de uma lâmpada, um número telefônico que chega a uma central, até mesmo os dados e suas faces. No entanto,
em várias situações, esse tipo de informação não está disponível. Também tivemos exemplos
dessas situações, tais quais o sexo de um filho que nasceu e o resultado do lançamento de duas moedas.
Para estes casos, como podemos lidar com eles numericamente? Uma forma natural de fazer
isso é contar quantas vezes uma coisa aparece.
\begin{example}
  Considere uma moeda lançada duas vezes. Seja X a função definida no espaço e que é
igual ao número de caras nos lançamentos. Vale que:
\begin{center}
  \begin{table*}[h!]
  \caption{Variável Aleatória de Caras}
  \centering
    \begin{tabular}{| c | c |}
      \hline
      Espaço amostral & Valores de X\\
      \hline
      C C & 2\\
      C \(\overline{C}\) & 1\\
      \(\overline{C}\) C & 1\\
      \(\overline{C}\) \(\overline{C}\) & 0\\
      \hline
    \end{tabular}
  \end{table*}
\end{center}
  Observa-se desta tabela que a variável aleatória associada ao evento ``moeda caiu cara" assume os valores
 \(X(CC) = 2, X(C\overline{C})=1, X(\overline{C}C)=1), X(\overline{CC}) = 0.\)
\end{example}
\begin{example}
  Dado um lote de 4 peças, das quais 2 são defeituosas, retiram-se peças até que as duas defeituosas
sejam retiradas. Coloque como X o número de peças retiradas. Temos:
\begin{center}
  \begin{table}[h]
  \caption{Número de Peças Retiradas}
  \centering
    \begin{tabular}{| c | c |}
      \hline
      Espaço Amostral & Valores de X\\
      \hline
      D D & X(D, D) = 2\\
      D P D & X(D, P, D) = 3\\
      P D D & X (P, D, D) = 3\\
      P P D D & X(P, P, D, D) = 4\\
      P D P D & X(P, D, P, D) = 4\\
      D P P D & X(D, P, P, D) = 4\\
      \hline
    \end{tabular}
  \end{table}
\end{center}
\end{example}
  Em outras palavras, é interessante associar, a cada ponto do espaço amostral, um número real. Essa associação é
chamada \textit{variável aleatória}. Formalmente, podemos escrever a seguinte definição:
\begin{def*}
  Uma variável aleatória é uma função \(X:\Omega \rightarrow \mathbb{R}\) definida num espaço amostral e que assume valores reais.
Sua imagem será denotada por \(R_{X}\). \(\square\)
\end{def*}
  Também é importante transmitir a noção de finitude, ou de quantidades não contínuas de valores.
 \begin{def*}
   As variáveis aleatórias que assumem valores em um conjunto enumerável serão denominadas discretas. Variáveis aleatórias que assumem valores
num intervalo da reta real serão denominadas contínuas.\(\square\)
 \end{def*}
  Os eventos associados a \(\Omega \) são ``relacionados'' a eventos associados com \(R_{X}\) a partir 
da seguinte definição:
\begin{def*}
  Seja o espaço amostral \(\Omega \). Seja X uma variável aleatória com imagem \(R_{X}\). Tome A
um evento em \(\Omega \) e B um evento em \(R_{X}\). Diremos que os eventos A e B são equivalentes se 
  \[
    A = \{\omega \in \Omega : X(\omega )\in B\}.\quad\square
  \]
\end{def*}
\begin{def*}
  Seja A um evento em \(\Omega \) e B um evento em \(R_{X}\). Definimos a probabilidade de B como
 \(\mathbb{P}_{X}(B) = \mathbb{P}(A),\) em que \(A = \{\omega \in \Omega : X(\omega )\in B\}.\quad\square\)
\end{def*}
  Denotaremos por \(\mathbb{P}_{X}\) a medida de probabilidade induzida por X em \(R_{X}\), tal que \((R_{X}, \cdot , \mathbb{P}_{X})\) será o espaço
de probabilidade induzido pela variável aleatória.
\subsection{Distribuição de Probabilidade}
  Vamos nos restringir às variáveis aleatórias discretas. Para conhecermos uma variável aleatória,
além de seus valores, precisamos ter em mente as probabilidades associadas a elas. Nisto, entra a ideia
de distribuição de probabilidade.
\begin{def*}
  A distribuição de probabilidade de uma variável aleatória discreta X, definida em um espaço amostral S,
é uma tabela que associa a cada valor de X sua probabilidade. Em outras palavras, 
  \[
    F(x) = \mathbb{P}(X\in (-\infty, x]) = \mathbb{P}(X\leq x),
  \]
  em que x percorre todos os reais.\(\square\)
\end{def*}
\begin{example}
  Vamos olhar para a distribuição de probabilidade da variável aleatória do caso das moedas.
Para cada valor de X, determinamos os pontos amostrais nos quais X é igual a tal valor, ou seja,
a imagem inversa de X. Vamos observar na tabela:
\begin{center}
  \begin{table}[h]
  \caption{Valores de X, probabilidades e pontos amostrais}

  \centering
    \begin{tabular}{| c | c | c |}
      \hline
      Valores de X & Pontos Amostrais & Probabilidades\\
      \hline
      0 & \(\overline{C}\overline{C}\) & \(\frac{1}{4}\)\\
      1 & \(\overline{C}C, C\overline{C}\) & \(\frac{1}{2} = \frac{1}{4} + \frac{1}{4}\)\\
      2 & CC & \(\frac{1}{4}\)\\
      \hline
    \end{tabular}
  \end{table}
\end{center}
  Os valores das probabilidades são calculados da seguinte forma:
 \begin{align*}
   &\mathbb{P}[X = 0] = \mathbb{P}(\overline{CC}) = \frac{1}{4}\\
   &\mathbb{P}[X = 1] = \mathbb{P}(\overline{C}C) = \frac{1}{2}\\
   &\mathbb{P}[X = 2] = \mathbb{P}(CC) = \frac{1}{4}.
 \end{align*}
\end{example}
\begin{example}
  Consideremos o experimento de lançar um dado sucessivamente sobre uma superfície plana. 
Analisemos quantos lançamentos o número 6 ocorre pela primeira vez - evento que denotaremos por X.
Temos, para todo \(n\geq 1\), 
  \[
    \mathbb{P}(X = n) = \biggl(\frac{5}{6}\biggr)^{(n-1)}\frac{1}{6}.
  \]
  De fato, pelos lançamentos serem independentes, a probabilidade de que não ocorra 6 nos
(n-1) primeiros lançamentos, mas que ocorra no n-ésimo lançamento, é dada pela fórmula dada acima.
\end{example}
\begin{lemma*}
  A função de distribuição de uma variável aleatória X satisfaz as seguintes condições:
 \begin{itemize}
   \item[a)] \(0\leq F(x)\leq 1\)
   \item[b)] F(x) é não decrescente e é contínua à direita
   \item[c)] \(\lim_{x\to \infty}F(x) = 0\) e \(\lim_{x\to \infty}F(x) = 1.\)
 \end{itemize}
\end{lemma*}
\begin{proof*}
  Isso será, essencialmente, um comentário sobre a ideia da prova.

  a) Segue de que F(x) representa uma probabilidade, ou seja, \(0\leq F(x)\leq 1.\)

  b) Se \(x_{1}\leq x_{2},\) então \(\{\omega \in \Omega : X(\omega ) < x_{1}\}\subseteq{\{\omega \in \Omega : X(\omega )\leq x_{2}\}}\) e, assim, \(\mathbb{P}(\{\omega \in \Omega : X(\omega )[2]\leq x_{1}\})\leq 
  \mathbb{P}(\omega \in \Omega : X(\omega )\leq x_{2}),\) ou seja, \(F(x_{1})\leq F(x_{2}).\)

  Para provar a continuidade à direita, seria preciso o seguinte resultado que sai do escopo do curso:
 \begin{quote}
   ``Se uma sequência de eventos \(A_{n}\) é decrescente e se aproxima de um evento A, então a sequência
   das probabilidades \(\mathbb{P}(A_{n})\) também é decrescente e tem limite \(\mathbb{P}(A).\)''
 \end{quote}
 Assumindo esse resultado, consideramos uma sequência \(\{x_{n}\}\) de números reais que seja decrescente e que
 \(\lim_{n\to \infty}x_{n} = x.\)  Assim, a sequência de eventos \([X\leq x_{n}]\) é decrescente e se aproxima de \([X\leq x].\) 
 Pela propriedade que citada, segue a continuidade à direita.

 c) Para uma sequência de eventos \(A_{n}\) que cresce para um evento A, vale uma propriedade análoga - 
\(\mathbb{P}(A_{n})\) converge para \(\mathbb{P}(A)\). Assim, tome \(\{x_{n}\}\) uma sequência de números reais
que tende a infinito. Assim, \([X\leq x_{n}]\) é uma sequência que tende ao evento \([X < \infty]\), tal que \(\mathbb{P}[X\leq x_{n}]\) 
converge para \(\mathbb{P}[X <\infty]\), que é trivialmente o espaço todo, cuja probabilidade é 1. Para demonstrar a segunda parte,
considera-se uma sequência \(\{x_{n}\}\) que tende a \(-\infty\), ou seja, \([X\leq x_{n}]\) tende ao vazio \(\emptyset\) e, portanto,
 \(F(x_{n}) = \mathbb{P}[X\leq x_{n}].\) \qedsymbol
\end{proof*}
\begin{example}
Seja 
  \[
    F(x)  = \left\{\begin{array}{ll}
        0,\quad x < 0;\\
        \frac{1}{2},\quad 0\leq x < 1;\\
        1,\quad x\geq 1.
      \end{array}\right.
  \]
  Essa F é uma função de distribuição?

  Ela é, de fato. Para ver isso, note que, como \(F(x) = 0\) para \(x < 0\) e \(F(x) = 1\) para 
 \(x\geq 1\),
  \[
    \lim_{x\to -\infty} F(x) = 0\quad\&\quad \lim_{x\to +\infty}F(x) = 1
  \]
  Além disso, a continuidade nos reais entre 0 e 1 é simples. Para os extremos, temos 
    \[
      F(0) = \lim_{x\to 0^{+}}F(x) = \frac{1}{2}\quad\&\quad F(1) = \lim_{x\to 1^{+}}F(x) = 1.
    \]
  Por fim, F é não decrescente pela sua definição.  
\end{example}
\begin{def*}
  A função de probabilidade de uma variável aleatória discreta X é uma que atribui probabilidade
a cada um dos possíveis valores \(x_{i}\) assumidos pela variável aleatória X, isto é, 
  \[
    p(x_{i}) = \mathbb{P}(X = x_{i}) = \mathbb{P}(\{\omega \in \Omega (\omega ): X(\omega ) = x_{i}\}),\quad i = 1, 2, \cdots, n.
  \]
  Além disso, \(p(x_{i})\) deve satisfazer 
    \[
      0\leq p(x_{i})\leq 1,\quad i = 1, \cdots, n
    \]
  e 
    \[
      \sum\limits_{i=1}^{n}p(x_{i}) = 1.\quad \square
    \]
\end{def*}

\subsection{EXTRA: Densidade de Probabilidade}
  As densidades de probabilidade surgem para tratar das variáveis aleatórias contínuas. Um dos problemas 
que surgem é que a soma dos valores em quantidades não enumeráveis de números positivos não pode ser igual a um.
  Com isso, definimos a densidade de probabilidade como uma função não negativa tal que sua integral, avaliada
num dado intervalo, equivale à probabilidade da variável pertencer a este intervalo. Além disso, para ser condizente com
a probabilidade total ser 1, impõe-se que a integral estendida à reta toda seja um.
\begin{def*}
  A densidade de probabilidade de uma variável aleatória contínua é uma função \(f(x)\geq 0\) tal que 
    \[
      \int_{-\infty}^{+\infty}f(x)dx = 1.
    \]
Além disso, a probabilidade de uma variável aleatória X pertencer a um intervalo da forma \((a, b]\) é dada por 
  \[
    \mathbb{P}[a < X\leq b] = \int_{a}^{b}f(x)dx.\quad \square
  \]
\end{def*}
\begin{example}
  Seja \(f(x) = x\) para \(0\leq x\leq 1\) e \(f(x) = 2 - x\) para \(1\leq x\leq 2\). No complementar desses dois,
coloque \(f(x)=0.\) Note que 
  \[
    \int_{0}^{2}f(x)dx = \int_{0}^{1}xdx + \int_{1}^{2}2-xdx = 1.
  \]
  Vamos calcular, também, as probabilidades \(\mathbb{P}[0\leq X\leq 0.8].\) Segue que 
    \[
      \mathbb{P}[0\leq X\leq 0.8]=\int_{0}^{0.8}xdx = \frac{1}{2}x^{2}\biggl|_{0}^{0.8}\biggr. = \frac{1}{2}(0.8)^{2} = 0.32.
    \]
  e 
    \[
      \mathbb{P}[0.3\leq X\leq 1.5] = \int_{0.3}^{1}xdx + \int_{1}^{1.5}2-xdx = 0.83.
    \]
\end{example}
\newpage

\section{Aula 06 - 10/10/2023}
\subsection{Motivações}
\begin{itemize}
  \item Esperança
\end{itemize}
\subsection{Esperança Discreta}
  A esperança matemática, ou apenas esperança, é uma quantidade associada às variáveis aleatórias e que representa,
por exemplo, a média dos valores do resultado de um experimento repetido uma sequência muito grande de vezes, sempre com
respeito aos extremos do intervalo. É um conceito essencial para estudar futuramente a noção de momento, de variância e de desvio padrão.
Sem mais delongas, formalizaremos a seguir as bases dessa ideia, juntamente de exemplos de como calculá-la.
  
\begin{def*}
  A esperança de uma variável aleatória discreta X, definida num espaço amostral \(\Omega \) no qual está definida uma
probabilidade \(\mathbb{P},\) é definida por 
  \[
    \mathbb{E}(X) = \sum\limits_{\omega \in \Omega }^{}X(\omega )\mathbb{P}(\omega ),
  \]
desde que \(\sum\limits_{\omega \in \Omega }^{}|X(\omega )|\mathbb{P}(\omega ) < \infty. \square\)
\end{def*}
  Um resultado interessante é que a esperança pode ser expressa por meio da função de distribuição previamente vista:
\begin{lemma*}
  A esperança matemática de uma variável aleatória discreta X que assume os valores \(x_{i}\) para \(i = 1, 2, \cdots\), com
respectivas probabilidades \(\mathbb{P}[X=x_{i}],\) é dada por 
  \[
    \mathbb{E}(X) = \sum\limits_{i=1}^{\infty}x_{i}\mathbb{P}[X=x_{i}].
  \]
\end{lemma*}
\begin{proof*}
  A ideia dessa prova é, a partir da definição da esperança, obtermos a expressão desejada e vice-versa.
Denote os pontos do espaço amostral por \(\omega_{j}, j=1, 2, \cdots\). Partindo do ponto de que a série 
 \(\sum\limits_{i=1}^{n}X(\omega_{j})\mathbb{P}(\omega_{j})\) é absolutamente convergente, um teorema de análise
 matemática afirma que podemos reordenar seus termos como quisermos. Faremos isso da seguinte forma:
\begin{align*}
  \mathbb{E}(X) &= \color{blue}\sum\limits_{j=1}^{\infty}X(\omega_{j})\mathbb{P}(\omega_{j}) = \color{red}\sum\limits_{i=1}^{\infty}\biggl[\sum\limits_{j:X(\omega_{j})=x_{i}}^{}X(\omega_{j})\mathbb{P}(X(\omega_{j}))\biggr]\\
                &= \color{green}\sum\limits_{i=1}^{\infty}\biggl[\sum\limits_{j:X(\omega_{j}) = x_{i}}^{}x_{i}\mathbb{P}(X(\omega_{j}))\biggr]=\sum\limits_{i=1}^{\infty}\biggl[x_{i}\sum\limits_{j:X(\omega_{j})=x_{i}}^{}\mathbb{P}(X(\omega_{j}))\biggr]\\
                &= \color{magenta}\sum\limits_{i=1}^{\infty}x_{i}\mathbb{P}[X = x_{i}].
\end{align*}
  Vamos entender o que aconteceu por partes. Para facilitar a compreensão, há um guia por cor a seguir:
 \begin{itemize}
   \item[\textbf{Azul)}] Neste passo, escrevemos a definição da esperança.
   \item[\textbf{Vermelho)}] Utilizamos a convergência absoluta da série (\(\sum\limits_{\omega \in \Omega }^{}|X(\omega )|\mathbb{P}(\omega ) < \infty\) por definição) para
fazer a seguinte reordenação: Somamos primeiramente os termos nos quais a variável aleatória, quando calculada em \(\omega_{j}\), vale \(x_{i}\). Isso resulta na mudança de índice de j
para i, ou seja, após essa primeira soma, realizamos uma soma infinita em i ao invés de j.
   \item[\textbf{Verde)}] Como os termos selecionados são os que \(X(\omega_{j})\) vale \(x_{i}\), trocamos a expressão \(X(\omega_{j})\mathbb{P}(X(\omega_{j}))\) por
 \(x_{i}\mathbb{P}(X(\omega_{j}))\) primeiro, fazendo com que \(x_{i}\) perca a dependência no índice j e possa ser retirado da primeira soma. Um processo similar será aplicado em
 \(\mathbb{P}(X(\omega_{j})),\) que é o próximo e último passo.
   \item[\textbf{Magenta)}] Por estarmos considerando os termos onde\(X(\omega_{j})\) vale \(x_{i}\), trocamos a expressão \(\mathbb{P}(X(\omega_{j}))\) por \(\mathbb{P}(X = x_{i})\), 
obtendo justamente a expressão do enunciado.
 \end{itemize}
 Como foi mencionado previamente, basta fazer o caminho oposto, partindo de \(\mathbb{E}(X) = \sum\limits_{i=1}^{\infty}x_{i}\mathbb{P}[X=x_{i}]\) e, a partir de 
 reordenações, chegar em \(\sum\limits_{j=1}^{\infty}X(\omega_{j})\mathbb{P}(X(\omega_{j})) = \sum\limits_{\omega \in \Omega }^{}X(\omega )\mathbb{P}(\omega ).\) \qedsymbol
\end{proof*}
  Outra propriedade muito importante tanto da esperança quanto das variáveis aleatórias é a linearidade. Não provaremos ela para
as variáveis aleatórias, mas isso quer dizer que, para variáveis aleatórias X e Y, vale para qualquer \(\Omega \ni \omega \)
  \[
    (X+Y)(\omega ) = X(\omega ) + Y(\omega )\quad\text{e}\quad (cX)(\omega ) = cX(\omega ).
  \]
  Precisamos disto para provas a mesma cosia para a esperança. De fato, 
 \begin{lemma*}
   Se as esperanças das variáveis aleatórias X e Y existem, então existe a esperança de X + Y. Além disso, se c é uma constante, temos
  \begin{itemize}
    \item[i)]\(\mathbb{E}(X+Y) = \mathbb{E}(X)+\mathbb{E}(Y)\);
    \item[ii)] \(\mathbb{E}(cX) = c \mathbb{E}(X).\)
  \end{itemize}
 \end{lemma*}
 \begin{proof*}
   Começamos mostrando que \(\mathbb{E}(X+Y)\) existe. Isso baseia-se nas propriedades de somas infinitas e módulo. De fato, 
     \[
       \mathbb{E}(X+Y) = \sum\limits_{\omega \in \Omega }^{}(X+Y)(\omega)\mathbb{P}(\omega) = \sum\limits_{\omega\in \Omega}^{}(X(\omega)+Y(\omega ))\mathbb{P}(\omega).
     \]
Assim, para que \(\mathbb{E}(X+Y)\) existe, é preciso que essa série seja finita em módulo. De fato, 
  \[
    \sum\limits_{\omega \in \Omega }^{}|X(\omega)+Y(\omega )|\mathbb{P}(\omega )\leq \sum\limits_{\omega \in \Omega }^{}(|X(\omega )| + |Y(\omega )|)\mathbb{P}(\omega ) = \sum\limits_{\omega \in \Omega }^{}|X(\omega )|\mathbb{P}(\omega ) + \sum\limits_{\omega \in \Omega }^{}|Y(\omega )|\mathbb{P}(\omega ).
  \]
Note que, como \(\mathbb{E}(X)\) e \(\mathbb{E}(Y)\) existem por hipótese, \(\sum\limits_{\omega \in \Omega }^{}|X(\omega )|\mathbb{P}(\omega ) < \infty\) e \(\sum\limits_{\omega \in \Omega }^{}|Y(\omega )|\mathbb{P}(\omega ) < \infty\), ou seja, 
  \[
    \sum\limits_{\omega \in \Omega }^{}|X(\omega)+Y(\omega )|\mathbb{P}(\omega )\leq \sum\limits_{\omega \in \Omega }^{}(|X(\omega )| + |Y(\omega )|)\mathbb{P}(\omega ) = \sum\limits_{\omega \in \Omega }^{}|X(\omega )|\mathbb{P}(\omega ) + \sum\limits_{\omega \in \Omega }^{}|Y(\omega )|\mathbb{P}(\omega ) < \infty.
  \]
Logo, \(\mathbb{E}(X+Y)\) existe. Além disso, segue da primeira expressão, isto é, 
  \[
   \mathbb{E}(X+Y) = \sum\limits_{\omega \in \Omega }^{}(X+Y)(\omega)\mathbb{P}(\omega) = \sum\limits_{\omega\in \Omega}^{}(X(\omega)+Y(\omega ))\mathbb{P}(\omega),
  \]
  que basta quebrar a série em duas para obter a expressão (i):
    \[
     \mathbb{E}(X+Y) = \sum\limits_{\omega\in \Omega}^{}(X(\omega)+Y(\omega ))\mathbb{P}(\omega) = \sum\limits_{\omega \in \Omega }^{}X(\omega )\mathbb{P}(\omega ) + \sum\limits_{\omega \in \Omega }^{}Y(\omega )\mathbb{P}(\omega ) = \mathbb{E}(X) + \mathbb{E}(Y),
    \]
  como queríamos. Por fim, tome c uma constante real. Então, 
    \[
      \mathbb{E}(cX) = \sum\limits_{\omega \in \Omega }^{}(cX)(\omega )\mathbb{P}(\omega ) = \sum\limits_{\omega \in \Omega }^{}cX(\omega )\mathbb{P}(\omega ) = c \sum\limits_{\omega \in \Omega }^{}X(\omega )\mathbb{P}(\omega ).
    \]
  Portanto, \(\mathbb{E}(cx) = c \mathbb{E}(x)\). \qedsymbol
   \end{proof*}
   Vamos ver um exemplo antes de seguir para a esperança contínua. 
  \begin{example}
    Uma loteria vende 100 bilhetes, cada um valendo R\$ 1,20. O bilhete sorteado ganhará um prêmio de R\$100,00.
  Qual é a esperança de seu ganho se você comprar um bilhete?
    
    Vamos designar por X a variável aleatória que representa o ganho. Se seu bilhete estiver entre os 99 que não ganham,
você pagou 1,20, ou seja, X assume o valor -1,20 em \(\frac{99}{100} = 0.99\) dos casos. Caso tenha a sorte de comprar o 
bilhete sorteado, X assume o valor \(100,00 - 1,20 = 98,80\), o que ocorre em \(\frac{1}{100} = 0.01\) dos casos. Assim,
a esperança de ganho é dada por 
  \[
    \mathbb{E}(X) = -1,20\times 0,99 + 98,80\times 0.01 = -0,20
  \]
  Como a esperança representa uma ``média'' dos resultados, na versão do jogo da loteria, uma esperança negativa quer dizer que
haverá uma perda na maioria dos casos, ou seja, há uma tendência do jogador perder dinheiro a longo prazo.
  \end{example}
\subsection{Esperança Contínua}
  Como no cálculo, faremos a passagem de quantidades discretas somadas para quantidades contínuas integradas. Em outras palavras,
se a função de distribuição da variável aleatória X é contínua, a esperança será definida da seguinte forma:
\begin{def*}
  A esperança de uma variável aleatória X, com densidade de probabilidade f(x), será dada por 
    \[
      \mathbb{E}(X) = \int_{-\infty}^{\infty}xf(x)dx.
    \]
\end{def*}
  Como a integral, assim como a soma, é linear, o lema provado que mostra a linearidade da esperança discreta permanece verdadeiro no caso contínuo. Vejamos, agora,
um exemplo da esperança contínua
\begin{example}
  Calcule a esperança da variável aleatória X, cuja densidade de probabilidade é dada por 
  \[
    f(x) = \left\{\begin{array}{ll}
        2x,\quad 0\leq x\leq 0.5,\\
        -\frac{2}{3}x + \frac{4}{3},\quad 0.5\leq x\leq 2\\
        0,\quad \text{caso contrário}
      \end{array}\right.
  \]

  Pela definição que vimos, segue que 
  \[
     \mathbb{E}(X) = \int_{-\infty}^{\infty}xf(x)dx.
  \]
  Antes de fazer a conta, vamos ver os possíveis valores da integral de xf(x), com base na definição de f:
  \[
   \int_{-\infty}^{\infty}xf(x)dx = \left\{\begin{array}{ll}
       \int_{0}^{0.5}x(2x)dx,\quad 0\leq x\leq 0.5\\
       \int_{0.5}^{2}x \biggl(-\frac{2}{3}x + \frac{4}{3}\biggr)dx,\quad 0.5\leq x\leq 2\\
       \int_{-\infty}^{a}x\times 0dx, a < 0, \text{ ou } \int_{b}^{\infty}x\times 0dx, b > 2.
     \end{array}\right.
 \]
  Com base nisso, a esperança será dada pela soma dessas integrais: 
  \begin{align*}
    \mathbb{E}(x) &= \int_{-\infty}^{a}x\times 0dx + \int_{0}^{0.5}x(2x)dx + \int_{0.5}^{2}x \biggl(-\frac{2}{3}x + \frac{4}{3}\biggr)dx + \int_{b}^{\infty}x\times0dx \\
                  &= 0 + \int_{0}^{0.5}x(2x)dx + \int_{0.5}^{2}x \biggl(-\frac{2}{3}x + \frac{4}{3}\biggr)dx + 0 \\
                  &= \frac{2}{3}x^{3}\biggl|_{0}^{0.5}\biggr. + \biggl(-\frac{2}{3}\biggr)\frac{1}{3}x^{3}\biggl|_{0.5}^{2}\biggr. + \frac{4}{3}\frac{1}{2}x^{2}\biggl|_{0.5}^{2}\biggr.\\
                  &= \frac{1}{12} - \frac{63}{36} + \frac{2}{3}\biggl(4-\frac{1}{4}\biggr) = \frac{30}{36} = 0.8333\cdots,
  \end{align*}
  em que assume-se que \(a < 0\) e que \(b > 0.\)
\end{example}
\newpage

\section{Aula 07 - 17/10/2023}
\subsection{Motivações}
\begin{itemize}
  \item Trabalhando com Esperança;
  \item Introdução à Variância.
\end{itemize}
\subsection{Esperança}
  Antes de mais nada, afirmamos mais uma propriedade das esperanças
 \begin{lemma*}
   Sejam X e Y variáveis aleatórias independentes cujos valores esperados existam. Então, 
     \[
       \mathbb{E}(XY) = \mathbb{E}(X)\mathbb{E}(Y).
     \]
 \end{lemma*}
 \begin{proof*}
   Vamos provar o caso discreto. Sejam X, Y variáveis aleatórias independentes cujas esperanças são \(\mathbb{E}(X), \mathbb{E}(Y)\). Como elas são independentes,
   \(\mathbb{P}(X)\mathbb{P}(Y) = \mathbb{P}(X\cap Y)\), o que equivale a \(\mathbb{P}(X\setminus{Y}) = \mathbb{P}(X)\). Por definição, 
   \[
     \mathbb{E}(XY) = \sum\limits_{\omega \in \Omega }^{}(XY)(\omega )\mathbb{P}(\omega ) = \sum\limits_{\omega \in \Omega }^{}X(\omega)Y(\omega )\mathbb{P}(\omega )
   \]
   Utilizando o lema para expressá-la como a função de distribuição, sejam \(x_{i}, i=1, 2, \cdots\) os valores
com probabilidades \(\mathbb{P}[X = x_{i}]\) e \(y_{j}, j=1, 2, \cdots\) a mesma coisa com \(\mathbb{P}[Y=y_{j}]\) no lugar. Assim, 
  \[
    \mathbb{E}(XY) = \sum\limits_{i=1}^{\infty}\sum\limits_{j=1}^{\infty}x_{i}y_{j}\mathbb{P}[X=x_{i}\cap Y=y_{j}] = \sum\limits_{i=1}^{\infty}\sum\limits_{j=1}^{\infty}x_{i}y_{j}\mathbb{P}[X=x_{i}]\mathbb{P}[Y=y_{j}] = \sum\limits_{i=1}^{\infty}x_{i}\mathbb{P}[X=x_{i}]\sum\limits_{j=1}^{\infty}y_{j}\mathbb{P}[Y=y_{j}]
  \]
  Note que, utilizando o lema novamente, as expressões das esperanças de X e Y são exatamente 
    \[
      \sum\limits_{i=1}^{\infty}x_{i}\mathbb{P}[X=x_{i}]\quad\text{e}\quad \sum\limits_{j=1}^{\infty}y_{j}\mathbb{P}[Y=y_{j}],
    \]
ou seja, obtivemos que, portanto,
  \[
    \mathbb{E}(XY) = \mathbb{E}(X)\mathbb{E}(Y).\text{\qedsymbol}
  \]

 \end{proof*}
\begin{example}
  Considere a variável aleatória X que denota o tempo, em minutos, para o processamento de um produto. A função de probabilidade de X é 
 \begin{center}
   \begin{table}[h!]
   \centering
     \begin{tabular}{| c | c c c c c c |}
       \hline 
       \(x_{i}\) & 2 & 3 & 4 & 5 & 6 & 7\\
       \hline
       \(\mathbb{P}(X = x_{i})\) & 0.1 & 0.1 & 0.3 & 0.2 & 0.2 & 0.1\\
       \hline
     \end{tabular}
   \end{table}
 \end{center}
\begin{itemize}
  \item[a)] Calcule o valor de \(\mathbb{E}(X).\)
  \item[b)] Calcule o valor de \(\mathbb{E}(2 + X)\)
\end{itemize}
  
  a) Utilizando a fórmula para esperança discreta, temos 
    \[
      \mathbb{E}(X) = 2\times 0.1 + 3\times 0.1 + 4\times 0.3 + 5\times 0.2 + 6\times 0.2 + 7\times 0.1 = 0.2 + 0.3 + 1.2 + 1.0 + 1.2 + 0.7 = 4.6
    \]

  b) Como a esperança age de maneira linear, \(\mathbb{E}(2 + X) = 2 + \mathbb{E}(X).\) Calculamos \(\mathbb{E}(X)\) no item (a), tal que 
    \[
      \mathbb{E}(2+x) = 2 + 4.6 = 6.6
    \]
\end{example}
\begin{example}
  A demanda diária de um supermercado (em centenas de quilos) pode ser descrita pela variável aleatória X com função densidade 
    \[
      f(x) = \left\{\begin{array}{ll}
          \frac{2x}{3},\quad 0\leq x <1,\\
          \frac{-x}{3} + 1,\quad 1\leq x <3\\
          0,\quad \text{caso contrário}.
        \end{array}\right.
    \]
  Calcule \(\mathbb{E}(X).\)

  Utilizando a fórmula para a esperança contínua, 
    \[
      \mathbb{E}(X) = \int_{0}^{1}\frac{2x}{3}xdx + \int_{1}^{3}\biggl(\frac{-x}{3} + 1\biggr)xdx = \frac{2}{9} + \frac{10}{9} = \frac{12}{9} = \frac{4}{3} 
    \]
\end{example}
\begin{example}
  Uma máquina corta arames conforme um comprimento específico dado. Em virtude de certas imprecisões do mecanismo de corte, o comprimento
do arame cortado (em polegadas), X, pode ser considerado como uma variável aleatória uniformemente distribuída sobre \([11.5, 12.5].\) O
comprimento especificado é 12 polegadas.
\begin{itemize}
  \item Se \(11.7\leq X < 12.2\), pode-se vender com um lucro de US\$0.25;
  \item Se \(X\geq 12.2\), corta-se e vende-se com um lucro de US\$0.10;
  \item Se \(X < 11.7\), o arame é refugado e perde-se US\$ 0.02.
\end{itemize}
Como podemos entender o lucro total por pedaço de arame cortado?
  
  Para este exercício, coloquemos \(\mathbb{P}(X\leq x) = F(x) = \int_{-\infty}^{x}f(s)ds = \int_{11.5}^{x}1ds = x - 11.5\) se \(11.5 < s < 12.5\), sendo este o intervalo no qual
X é uma variável aleatória distribuída uniformemente. Com isso, coloque 
  \[
    Y \left\{\begin{array}{ll}
        -0.02,\quad \text{se está em prejuízo }(X < 11.7)\\
        0.25,\quad \text{se está no ideal }(11.7\leq X < 12.2\\
        0.1,\quad \text{se não há prejuízo nem é ideal }(x\geq 12.2).
      \end{array}\right.
  \]
  Com estas informações, temos 
  \[
    \mathbb{E}(Y) = -0.02\times \underbrace{F_{X}(11.7)}_{0.2} + 0.25\underbrace{(F_{X}(12.2)-F_{X}(11.7))}_{0.5} + 0.1\underbrace{(1-F_{X}(12.2))}_{0.3} = 0.151
  \]
\end{example}
\subsection{Variância}
  Suponha que, associada à variável aleatória X, temos \(\mathbb{E}(X) = 2\). O que exatamente isso significa? Afinal, é importante que, qualitativamente,
não atrelemos a isso um significado errado, seja isso exagerar ou diminuir a informação carregada.
\newpage

\section{Aula 08 - 19/10/2023}
\subsection{Motivações} 
\begin{itemize}
  \item Variância;
\end{itemize}
\subsection{Variância}
\paragraph{} Continuando do ponto de partida, buscamos responder o significado da frase ``Associada à variável
aleatória X, temos \(\mathbb{E}(X) = 2\).''

  Ao considerarmos uma quantidade muito grande de realizações de X, quando calcula-se a média desses valores,
eles estarão, em média, próximos a 2. No entanto, podem estar muito distantes dele.
\begin{example}
  Suponhamos que X represente a duração da vida de lâmpadas que estejam sendo recebidas de um fabricante e que \(\mathbb{E}(X) = 1000\)horas.
Isto pode significar uma dentre \textbf{muitas coisas}. Por exemplo, que algumas delas vão estar um pouco acima de \(1000\) horas,
ou um pouco abaixo, mas giram em torno disso. Por outro lado, pode ser que todas estejam muito acima de mil e muito abaixo de mil.
Esse tipo de informação não é possível obter apenas com base na esperança.
\end{example}
\begin{def*}
  A \textbf{mediana} é o ponto a partir do qual todos os valores podem ser separados em 50\% acima ou 50\% abaixo. A \textbf{moda} é
o argumento máximo da distribuição de probabilidade. Matematicamente, 
  \[
    \text{Med}(X) \coloneqq \biggl\{x: F(x) = \int_{-\infty}^{x}f(x)dx = \frac{1}{2}\biggr\} ,\quad Mo(x) \coloneqq \text{arg}\max{f(x)}
  \]
  A \textbf{variância} é definida como 
    \[
      Var(X)\coloneqq \mathbb{E}\biggl[(X-\mathbb{E}(x))^{2}\biggr] = \mathbb{E}(X^{2}) - [\mathbb{E}(X)]^{2},
    \]
  em que \(\mathbb{E}(X^{2}) = \sum\limits_{i=1}^{\infty}x_{i}^{2}p(x_{i})\) é chamado \textbf{segundo momento central}.
  O \textbf{desvio} é definido por \((X-\mathbb{E}(X))^{2}\). Além disso, definimos como \textbf{desvio padrão} a 
raiz da variância 
  \[
    DP(X) \coloneqq  \sqrt[]{Var(X)} = \mathbb{E}\biggl[|X-\mathbb{E}(X)|\biggr].\quad\square
  \]
\end{def*}
  No caso contínuo, a esperança assume a forma 
    \[
      Var(X) = \underbrace{\int_{-\infty}^{\infty}x^{2}f(x)dx}_{\mathbb{E}(X^{2})} - \underbrace{\biggl[\int_{-\infty}^{\infty}xf(x)dx\biggr]^{2}}_{[\mathbb{E}(X)]^{2}}
    \]
  Algumas propriedades da variância: 
 \begin{lemma*}
   Sejam X, \(X_{1}, \cdots, X_{n}\) variáveis aleatórias e c uma constante real. Então, 
  \begin{itemize}
    \item[a)] Var(c) = 0;
    \item[b)] Var(c+X) = Var(X);
    \item[c)] \(Var(cx) =c^{2}Var(x).\)
    \item[d)] Se \(X_{1}, X_{2}, \cdots, X_{n}\) são independentes, 
      \[
        Var(X_{1}+X_{2}+\cdots+X_{n}) = Var(X_{1})+Var(X_{2})+\cdots+Var(X_{n}).
      \]
  \end{itemize}
 \end{lemma*}
 \newpage
\begin{example}
  Considere a variável aleatória X, que denota o tempo em minutos para o processamento de um produto. A função de probabilidade de X é 

 \begin{center}
  \begin{table}[h!]
  \centering
    \begin{tabular}{| c | c c c c c c |}
      \hline 
      \(x_{i}\) & 2 & 3 & 4 & 5 & 6 & 7\\
      \hline
      \(\mathbb{P}(X = x_{i})\) & 0.1 & 0.1 & 0.3 & 0.2 & 0.2 & 0.1\\
      \hline
    \end{tabular}
  \end{table}
\end{center}

 a) Calcule \(Var(X)\) e \(DP(X)\), sabendo que \(\mathbb{E}(X) = 4.6.\)

 Como \(Var(X) = \mathbb{E}(X^{2}) - [\mathbb{E}(X)]^{2} = \mathbb{E}(X^{2}) - (4,6)^{2},\) podemos reescrever como 
 \begin{align*}
   Var(X) &= \sum\limits_{x=2}^{7}x^{2}\mathbb{P}(X=x) - (4,6)^{2} = 2^{2}\cdot 0,1 + 3^{2}\cdot 0,1 + 4^{2}\cdot 0,3 + 5^{2}\cdot 0,2 + 6^{2}\cdot 0,2 + 7^{2}\cdot 0,1 - [4,6]^{2}\\
          &= 23,2 - [4,6]^{2} = 2,04.
 \end{align*}
 Com isso, o desvio padrão é 
   \[
     DP(X) = \sqrt[]{Var(X)} = \sqrt[]{2,04}\approx 1,42\text{min.}
   \]

 b) Encontre Var(2X) e DP(2X), sabendo que \(\mathbb{E}(X) = 4,6.\)

 Segue que \(Var(2X) = 2^{2}Var(X) = 4Var(X) = 4 \cdot 2,04 = 8,16\) e que \(DP(2X) = \sqrt[]{Var(2X)} = 2\sqrt[]{Var(X)}\approx 2,84.\)
\end{example}
\begin{example}
 A demanda diária de um supermercado (em centenas de quilos) pode ser descrita pela variável aleatória X com função densidade 
  \[
    f(x) = \left\{\begin{array}{ll}
        \frac{2x}{3},\quad 0\leq x <1,\\
        \frac{-x}{3} + 1,\quad 1\leq x <3\\
        0,\quad \text{caso contrário}.
      \end{array}\right.
  \]
Calcule Var(X) e DP(X), sabendo que \(\mathbb{E}(X)\approx 1,3333.\)

Temos \(Var(X) = \mathbb{E}(X^{2}) - [\mathbb{E}(X)]^{2}\), ou seja, 
\begin{align*}
  Var(X) &= \int_{-\infty}^{\infty}x^{2}f(x)dx - [\mathbb{E}(X)]^{2}\\
         &= \int_{0}^{1}x^{2}f(x)dx + \int_{1}^{3}x^{2}f(x)dx\\
         &= \int_{0}^{1}\frac{2}{3}x^{3}dx + \int_{1}^{3}x^{2}\biggl(-\frac{x}{3}+1\biggr)dx - [\mathbb{E}(X)]^{2}\\
         &= \frac{x^{4}}{6}\biggl|_{0}^{1}\biggr. + \biggl[\frac{x^{3}}{3}-\frac{x^{4}}{12}\biggr]\biggl|_{1}^{3}\biggr. - [\mathbb{E}(X)]^{2}\\
         &= \frac{2}{12} + 9 - \frac{81}{12} - \frac{1}{3} + \frac{1}{12} - [1,3333]^{2}\approx 0,38
\end{align*}
Além disso, o desvio padrão vale \(DP(X) = \sqrt[]{0,38}\approx 0,62.\)
\end{example}
\begin{example}
 Suponha a variável aleatória X tal que 
   \[
     \mathbb{P}(X=1) = p\quad\text{e}\quad \mathbb{P}(X=0) = 1-p,\quad p\in [0, 1].
   \]
Como podemos interpretar \(\mathbb{E}(X)\) e Var(X)?

Sendo essa variável aleatória categórica, segue que, para p = 0,8,
  \[
    \mathbb{E}(X) = \sum\limits_{x=0}^{1}x \mathbb{P}(X=x) = 0 \cdot 0,2 + 1 \cdot 0,8 = 0,8 = p
  \]
e a variância será 
  \[
    \mathbb{E}((X-\mathbb{E}(X))^{2}) = \sum\limits_{x=0}^{1}(x-p)^{2}\mathbb{P}(X=x) = p^{2}\cdot 1 + (1-p)^{2}p = p - p^{2} = p(1-p).
  \]
que é um modelo cuja variância é máxima quando p vale \(\frac{1}{2}\).
\end{example}
\newpage

\section{Aula 09 - 31/10/2023}
\subsection{Motivações}
\begin{itemize}
  \item a
\end{itemize}
\end{document}
