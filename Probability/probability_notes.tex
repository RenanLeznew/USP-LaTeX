\documentclass{article}
 \usepackage{amsmath}
 \usepackage{xcolor}
 \usepackage{amsthm}
 \usepackage{amssymb}
 \usepackage{pgfplots}
 \usepackage[utf8]{inputenc}
 \usepackage{amsfonts}
 \usepackage[margin=2.5cm]{geometry}
 \usepackage{graphicx}
 \usepackage[export]{adjustbox}
 \usepackage{fancyhdr}
 \usepackage[portuguese]{babel}
 \usepackage{hyperref}
 \usepackage{lastpage}
 \usepackage{mathtools}
 \usepackage[light, math]{iwona}
 \usepackage[T1]{fontenc}
 \setcounter{section}{-1}

 \pagestyle{fancy}
 \fancyhf{}

 \pgfplotsset{compat = 1.18}

 \hypersetup{
     colorlinks,
     citecolor=black,
     filecolor=black,
     linkcolor=black,
     urlcolor=black
 }
 \newtheorem*{def*}{\underline{Defini\c c\~ao}}
 \newtheorem*{theorem*}{\underline{Teorema}}
 \newtheorem*{lemma*}{\underline{Lema}}
 \newtheorem*{prop*}{\underline{Proposi\c c\~ao}}
 \newtheorem{example}{\underline{Exemplo}}
 \newtheorem*{proof*}{\underline{Prova}}
 \renewcommand\qedsymbol{$\blacksquare$}

 \rfoot{P\'agina \thepage \hspace{1pt} de \pageref{LastPage}}

 \begin{document}
 \begin{figure}[ht]
  \minipage{0.76\textwidth}
    \includegraphics[width=4cm]{icmc.png}
    \hspace{7cm}
    \includegraphics[height=4.9cm,width=4cm]{brasao_usp_cor.jpg}
  \endminipage  
\end{figure}

\begin{center}
  \vspace{1cm}
  \LARGE
  UNIVERSIDADE DE S\~AO PAULO

  \vspace{1.3cm}
  \LARGE
  INSTITUTO DE CI\^ENCIAS MATEM\'ATICAS E COMPUTACIONAIS - ICMC

  \vspace{1.7cm}
  \Large
  \textbf{Introdução à Probabilidade}

  \vspace{1.3cm}
  \large
  \textbf{Renan Wenzel - 11169472}

  \vspace{1.3cm}
  \large
  \textbf{Professor: Oilson Alberto Gonzatto Junior}

  \textbf{E-mail: oilson.agjr@icmc.usp.br}

  \vspace{5cm}
  \today
\end{center}

 \newpage

 \tableofcontents

 \newpage

\section{Informações (Possivelmente) Úteis}
\subsection*{Monitoria}
\begin{itemize}
  \item[Monitora:] Patrícia Stülp
  \item[E-mail:] \textit{patriciastulp2@gmail.com}
\end{itemize}
\subsection*{Datas das Provas}
  \subsubsection*{Mini provas}
 \begin{itemize}
   \item[i)] 29/08/2023;
   \item[ii)] 12/09/2023; 26/09/2023;
   \item[iii)] 10/10/2023; 24/10/2023;
   \item[iv)] 07/11/2023; 21/11/2023;
   \item[v)] 05/12/2023
 \end{itemize}
 \subsubsection*{(Talvez) P3}
  Pode não ocorrer, mas, a depender dos resultados das mini-provas, será dia 12/12/2023.
\subsection*{Bibliografia}
\begin{itemize}
  \item[Principal:] MEYER, P. L. ``Probabilidade: Aplicações à Estatística'', 2a edição, LTC, Rio de Janeiro, 2009.
  \item[Complementar:] ROSS, S. A. ``First Course in Probability", 8th edition, Pearson, 2010.
\end{itemize}

 \newpage
\section{Aula 01 - 22/08/2023}
\subsection{Motivações}
\begin{itemize}
  \item O que é aleatoriedade e probabilidade?
  \item Conceitos Fundamentais;
\end{itemize}
\subsection{Aleatoriedade, probabilidade e conceitos fundamentais}
  A probabilidade está nos conceitos bases da ciência atual, sendo resultado de uma revolução na ciência há um século atrás.
A noção de aleatoriedade, no entanto, é muito mais difícil de obter uma resposta.

  Começamos com um experimento E - um mecanismo gerado. Dele, obtemos um resultado \(\omega \). A estes resultados,
associamos um conjunto, chamado de evento \(A = \{\omega_{1}, \cdots, \omega_{k}\}\). Com estas ideias, associa-se um valor
a um evento, chamado probabilidade \(\mathbb{P}(A).\) Vamos compreender estas ideias mais a fundo.

\subsubsection{Experimentos}
  Experimentos podem ser distinguidos em alguns tipos. O primeiro deles é o determinístico. Nele,
o resultado obtido é determinado pelas condições sob as quais o experimento foi executado. A outra forma 
é conhecida como experimento aleatório, que engloba experimentos cujos resultados não sabemos \textit{a priori}, isto é,
 ainda que as condições iniciais sejam fixas, os resultados não podem ser previstos. Eles possuem as seguintes características:
 \begin{itemize}
   \item[a)] Mesmo repetindo várias vezes com as mesmas condições iniciais, o resultado pode mudar;
   \item[b)] Apesar da falta de exatidão, é possível descrever o conjunto de todos os resultados possíveis;
   \item[c)] Há uma regularidade nos resultados após ele ser repetido muitas vezes, permitindo uma modelagem matemática dele.
\subsubsection{Espaço Amostral}
  O espaço amostral denota todos os resultados que podem ocorrer ao realizar um experimento aleatório.
  
  \textbf{Observação:} O mecanismo gerador está limitado a um determinado conjunto de possibilidades de saídas.
 \end{itemize}
\begin{example}
  Se considerarmos características sócio demográficas de um grupo de pessoas, poderíamos ter
 \begin{itemize}
   \item[Sexo:)] \{Masculino, Feminino, Intersexo\}
   \item[Idade:)] \{0, 1, 2, ...\}
   \item[Estado civil:)] \{Solteiro, Casado, Viúvo, outros.\}
   \item[Renda familiar:)] \(\{x: x\in \mathbb{R}^{+}\}\)
 \end{itemize}
\end{example}
\begin{example}
  Dados os experimentos aleatórios, quais são os espaços amostrais?
 \begin{itemize}
   \item[\(E_{1}\))] Lançar uma moeda 2 vezes e observar as faces obtidas; \(\Omega =\{(C, C), (C, K), (K, C), (K, K)\}\)
   \item[\(E_{2}\))] Retirar uma carta de um barulho comum e observar o naipe; \(\Omega\)=\{``ouros'', ``copas'', ``paus'', ``espadas''\}
   \item[\(E_{3}\))] Duração de lâmpadas, deixando-as acesas até que queimem; \(\Omega = \{t: t\geq 0\}\)
   \item[\(E_{4}\))] Número de mensagens por dia entre uma empresa e um determinado cliente. \(\Omega = \{t: t\geq 0\}\)
 \end{itemize}
\end{example}
\subsubsection{Evento}
  Um evento representa qualquer dúvida que possa surgir sobre o resultado de um experimento. Em particular, podem ser visualizados como subconjuntos do espaço amostral. Com isso,
o próprio amostral é um evento, chamado evento certo, assim como o vazio é um evento, dito evento impossível.
\begin{example}
  Considere o resultado obtido com o lançamento de um dado de seis faces, equilibrado. O espaço amostral é \(\{1, 2, 3, 4, 5, 6\}\). Descrevamos os seguintes eventos:
 \begin{itemize}
   \item[1)] A = ``ocorrência do número 3'' = \{3\};
   \item[2)] B = ``sair a face de número 7'' = \(\emptyset\);
   \item[3)] C = ``sair um número menor ou igual a 6'' = \(\Omega \).
 \end{itemize}
\end{example}
\begin{example}
  Podemos considerar experimentos cujos resultados podem ser vetores. A exemplo, o preço de fechamento de determinadas
ações em uma data específica, como \(\omega = \)(PETR4, ITUB4, ..., AZUL4). Nesse contexto, um evento possível poderia ser 
a situação em que a média desse vetor de preços seja maior do que a média do dia anterior.
\end{example}
\subsubsection{Operações com Eventos}
  Veja que um experimento aleatório pode ser tão complicado quanto necessário. Buscamos, porém, buscar simplificações confiáveis para descrever com probabilidades
estes comportamentos, ou seja, estabelecer as propriedades básicas da função de probabilidade. Antes de mais nada, porém, torna-se necessário
saber como operar os eventos. 

  Como eventos são subconjuntos do espaço amostral, a operação entre eles é dada por meio das operações entre conjuntos - 
união, interseção, complemento, etc. Nesta lógica, compreendemos como
\begin{itemize}
  \item[] União de eventos - a capacidade do evento A OU do evento B ocorram;
  \item[] Interseção de eventos - a capacidade do evento A E do evento B ocorrerem simultaneamente.
  \item[] Complementar - a capacidade do evento A não acontecer
  \item[] Eventos mutuamente exclusivos - A e B não ocorrem simultaneamente, isto é, \(A\cap B = \emptyset\)
\end{itemize}
\begin{example}
  Um número entre 1 e 10 é selecionado ao acado. Considere A como o evento em que o número selecionado é múltiplo de 3 e B o conjunto em que o número selecionado é par. Então, 
 \(\Omega = \{1, 2, \cdots, 10\}, A = \{3, 6, 9\}, B = \{2, 4, 6, 8, 10\}\). O evento que ocorre nos dois é \(A\cap B=\{6\}\). O evento representando que o número seja um múltiplo de 3 ou
 um número par é \(A\cup B = \{2, 3, 4, 6, 8, 9, 10\}\). Alguns outros são: \(A\cap B^{c} = \{3, 9\}, A^{c}\cap B = \{2, 4, 8, 10\}.\)
\end{example}
\newpage
\section{Aula 02 - 24/08/2023}
\subsection{Motivações}
\begin{itemize}
  \item As definições de probabilidade;
  \item A probabilidade segundo Kolmogorov.
\end{itemize}
\subsection{Conceitos}
\paragraph{}As ideias desenvolvidas até aqui são as que Laplace desenvolveu, contendo toda a parte do cálculo
de probabilidade por meio da contagem de casos favoráveis e dos possíveis. No entanto, foram desenvolvidas outras
abordagens para lidar com as limitações da dependência na uniformidade das saídas, no número finito de resultados possíveis, etc.
A definição clássica de probabilidade é a razão entre o número de casos favoráveis e o de possíveis, ou seja, 
\begin{def*}
  Seja o evento A, associado a um espaço amostral finito e equiprovável, \(\Omega \). Definimos a probabilidade de ocorrência do evento A por: 
    \[
      \mathbb{P}(A) = \frac{\#(A)}{\#(\Omega )}.\quad \square
    \]
\end{def*}
  Richard von Mises buscou enxergar a probabilidade como algo que pode ser definido apenas para um gerador aleatório capaz de produzir uma sequência infinita de resultados.
A probabilidade, aqui, será a frequência limite do resultado nessa sequência. Ele baseou isso na ideia de que a aleatoriedade é um processo que produz resultados imprevisíveis
e não claramente determinados.
\begin{def*}
  Seja \(n_{A}\) o número de vezes que o evento A ocorre em n repetições independente de um mesmo experimento. Então, 
    \[
      \mathbb{P}(A) = \lim_{n\to \infty}\frac{n_{A}}{n},
    \]
    desde que o limite exista. \(\square\)
\end{def*}
 Essa definição mostrou-se importante até durante a contemporaneidade. No entanto, não é muito prático para fazer contas e encontrar probabilidades, 
sua força está em exibir a noção que a aplicabilidade traz. Além disso, ela funciona como uma ponte entre a primeira definição e a próxima que será vista.
Outro problema com essa é que, quando quantidades enormes de saídas surgem, torna-se impossível de usá-lo, pois não dá para saber o total de possibilidades.
  
  Assim, Kolmogorov estende a definição de probabilidade para espaços mais gerais, conhecido como a pessoa que formalizou a teoria da probabilidade. A ideia dele permite que
propostas mais flexíveis de probabilidades sejam usadas, saindo do limite de contabilidade finita e equiprovável da ideia de Laplace.
\begin{def*}
  Seja E um experimento aleatório e \(\Omega \) o espaço amostral associado. A cada evento A associamos um número real
 \(\mathbb{P}(A)\), denominado probabilidade de A, que satisfaz 
\begin{itemize}
  \item[P1)] \(\mathbb{P}(\Omega )=1;\)
    \item[P2)] \(0\leq \mathbb{P}(A)\leq 1,\) para todo A decorrente de \(\Omega \);
      \item[P3)] Se A e B forem eventos mutuamente exclusivos, então 
        \[
          \mathbb{P}(A\cup B) = \mathbb{P}(A) + \mathbb{P}(B);
        \]
      \item[P4)] Para qualquer sequência de eventos disjuntos dois-a-dois, \(A_{1}, A_{2}, \cdots, A_{n}\), tem-se 
        \[
          \mathbb{P}\biggl(\bigcup_{i=1}^{n}A_{i}\biggr) = \sum\limits_{i=1}^{n}\mathbb{P}(A_{i}).\quad \square
        \]
\end{itemize}
\end{def*}
  Seguem algumas propriedades:
 \begin{theorem*}
   Se \(\emptyset\) é um evento impossível, então \(\mathbb{P}(\emptyset) = 0.\)
 \end{theorem*}
 \begin{theorem*}
  Se \(A^{c}\) for o complementar de A, então \(\mathbb{P}(A^{c}) = 1 - \mathbb{P}(A).\)
 \end{theorem*}
\begin{theorem*}
  Se A e B são dois eventos quaisquer de \(\Omega \), então 
    \[
      \mathbb{P}(A\cup B) = \mathbb{P}(A) + \mathbb{P}(B) - \mathbb{P}(A\cap B).
    \]
\end{theorem*}
\begin{theorem*}
  Se \(A_{1}, A_{2}, \cdots, A_{i}\) são eventos dois-a-dois disjuntos, então 
  \begin{align*}
    \mathbb{P}(A_{1}\cup \cdots\cup A_{i}) &= \sum\limits_{i=1}^{n}\mathbb{P}(A_{i}) - \sum\limits_{i < j}^{n} \mathbb{P}(A_{i}\cap A_{j}) + \sum\limits_{i < j < r}^{n} \mathbb{P}(A_{i}\cap A_{j}\cap A_{r}) + \cdots\\
                                           &\cdots + (-1)^{n-1}\mathbb{P}(A_{1}\cap \cdots A_{n})
  \end{align*}
\end{theorem*}
\begin{example}
  Um lote é formado por 10 peças boas, 4 com defeitos menores e 2 com defeitos graves. Uma peça é escolhida ao acaso. Calcule a probabilidade de que 
 \begin{itemize}
   \item[a)] A peça não tenha defeito grave;
   \item[b)] A peça não tenha defeito;
   \item[c)] A peça seja boa ou tenha defeito grave.
 \end{itemize}
  a) Considerando A o conjunto de peças boas, B o de peças levemente defeituosas e C o de peças gravemente defeituosas, esses conjuntos são dois-a-dois disjuntos. Assim, 
    \[
      \mathbb{P}(C^{c}) = 1 - \mathbb{P}(C) = 1 - \frac{2}{16} = \frac{7}{8}.
    \]
    
  b) Com a notação anterior, 
    \[
      \mathbb{P}((B\cup C)^{c}) = \mathbb{P}(B^{c}\cap C^{c}) = \mathbb{P}(B^{c}) + \mathbb{P}(C^{c}) - \mathbb{P}(C^{c}\cup B^{c}) = \mathbb{P}(A) = \frac{10}{16} = \frac{5}{8}.
    \]

  c) Novamente, mantendo a anotação, 
    \[
      \mathbb{P}(A\cup C) = \mathbb{P}(A) + \mathbb{P}(C) = \frac{10}{16} + \frac{2}{16} = \frac{12}{16} = \frac{3}{4}.
    \]
\end{example}
\newpage

\section{Aula 03 - 31/08/2023}
\subsection{Motivações}
\begin{itemize}
  \item Probabilidade Condicional;
  \item Dependência de Eventos.
\end{itemize}
\subsection{A Probabilidade Condicional}
\begin{def*}
  Sejam dois eventos A e B associados ao mesmo espaço amostral \(\Omega \). A probabilidade condicional de A 
dado que ocorreu B é representada por \(\mathbb{P}(A|B\) e dada por 
  \[
    \mathbb{P}(A|B) = \frac{\mathbb{P}(A\cap B)}{\mathbb{P}(B)},\quad \mathbb{P}(B) > 0\quad \square.
  \]
\end{def*}
  Em particular, seguem duas representações para a probabilidade de dois eventos ocorrerem simultaneamente, sendo elas
  \begin{align*}
    &\mathbb{P}(A|B) = \frac{\mathbb{P}(A\cap B)}{\mathbb{P}(B)} \Rightarrow \mathbb{P}(A\cap B) = \mathbb{P}(A|B)\mathbb{P}(B)\\
    &\mathbb{P}(B|A) = \frac{\mathbb{P}(A\cap B)}{\mathbb{P}(A)} \Rightarrow \mathbb{P}(A\cap B) = \mathbb{P}(B|A)\mathbb{P}(A)\\
  \end{align*}
  \begin{example}
    Um dado de seis faces, equilibrado, é lançado e o número voltado para cima é obsecrado.
    \begin{itemize}
      \item[(a)] Se o resultado obtido for par, qual a probabilidade dele ser maior ou igual a 5?
      
    \item[(b)] Se o resultado obtido for maior ou igual a 5, qual a probabilidade dele ser par?
\end{itemize}

    Para o item a, o espaço amostral é \(\Omega = \{1, 2, 3, 4, 5, 6\}\). Considere os eventos
    A como o resultado de ser par e B o resultado obtido sendo maior ou igual a 5. Então, 
      \[
        \mathbb{P}(B|A) = \frac{\mathbb{P}(A\cap B)}{\mathbb{P}(A)} = \frac{\mathbb{P}(\{6\})}{\mathbb{P}(\{2, 4, 6\})} = \frac{1}{3};
      \]

      Para o item b, temos 
        \[
          \mathbb{P}(A|B) = \frac{\mathbb{P}(A\cap B)}{\mathbb{P}(B)} = \frac{\mathbb{P}(\{6\})}{\mathbb{P}(\{5, 6\})} = \frac{\frac{1}{6}}{\frac{2}{6}} = \frac{1}{2}.
        \]
  \end{example}
 \begin{def*}
   Os eventos A e B são independentes se a informação da ocorrência de B não altera a probabilidade atribuída ao evento A, isto é, 
     \[
       \mathbb{P}(A|B) = \mathbb{P}(A),
     \]
    ou, equivalentemente, 
    \[
      \mathbb{P}(A\cap B) = \mathbb{P}(A)\mathbb{P}(B).\quad\square
    \]
 \end{def*}
\begin{example}
  Uma moeda é viciada, de modo que a chance de sair cara é o dobro da de sair coroa.
  \begin{itemize}
    \item[(a)] Dê o espaço amostral

  \item[(b)] Calcule a probabilidade de ocorrer cara no lançamento desta moeda.
\end{itemize}

  (a) O espaço amostral desse evento é \(\Omega = \{\text{Cara, Coroa}\}\). Seja A o evento que cai cara e B o que cai coroa.

  (b) Sabemos que \(\mathbb{P}(A) + \mathbb{P}(B) = 1\) e que \(\mathbb{P}(A) = 2 \mathbb{P}(B)\), ou seja, 
    \[
      \mathbb{P}(A) + \frac{\mathbb{P}(A)}{2} = 1 \Rightarrow \mathbb{P}(A) = \frac{2}{3}.
    \]
\end{example}
\begin{example}
  Duas lâmpadas queimadas foram acidentalmente misturadas com seis boas. Se vamos testar as lâmpadas, uma por uma, até
encontrar duas defeituosas, qual é a probabilidade de que a última defeituosa seja encontrada no quarto teste?

  Estamos interessados em calcular a probabilidade do seguinte evento:
 \begin{align*}
   (\overline{D_{1}}\cap \overline{D_{2}}\cap D_{3}\cap D_{4})\cup(\overline{D_{1}}\cap D_{2}\cap \overline{D_{3}}\cap D_{4})\cup(D_{1}\cap \overline{D_{2}}\cap \overline{D_{3}}\cap D_{4})\\
   &\Rightarrow \mathbb{P}(\overline{D_{1}}\cap \overline{D_{2}}\cap D_{3}\cap D_{4})\cup(\overline{D_{1}}\cap D_{2}\cap \overline{D_{3}}\cap D_{4})\cup(D_{1}\cap \overline{D_{2}}\cap \overline{D_{3}}\cap D_{4})\\
   &= \mathbb{P}(\overline{D_{1}}\cap \overline{D_{2}}\cap D_{3}\cap D_{4}) + \mathbb{P}(\overline{D_{1}}\cap D_{2}\cap \overline{D_{3}}\cap D_{4}) + \mathbb{P}(D_{1}\cap \overline{D_{2}}\cap \overline{D_{3}}\cap D_{4}).
 \end{align*}
  Após manipulações algébricas e contas, chegamos em 
    \[
      \frac{1}{28} + \frac{1}{28} + \frac{1}{28} = \frac{3}{28}\approx 0,1071.
    \]
\end{example}
\begin{def*}
  Dizemos que \(A_{1}, A_{2}, \cdots, A_{n}\) formam uma partição de \(\Omega \) se eles são dois-a-dois disjuntos e a sua união é \(\Omega.\quad\square \)
\end{def*}
\begin{theorem*}
  Suponha que os eventos \(A_{1}, A_{2}, \cdots, A_{n}\) formam uma partição de \(\Omega \) e que todos têm probabilidade positiva. Então, para qualquer evento B, 
    \[
      \mathbb{P}(B) = \sum\limits_{i=1}^{n}\mathbb{P}(B|A_{i})\mathbb{P}(A_{i})
    \]
\end{theorem*}
\begin{example}
  Uma companhia produz circuitos integrados em três fábricas, sendo elas A, B e C. A fábrica A produz 40\% deles, e as outras produzem 30\% cada. As probabilidades de que um circuito integrado produzido por essas fábricas não funcione são 
 \(0,01; 0,04; 0,03\) respectivamente. Escolhido um circuito da produção conjunta das três fábricas, qual a probabilidade dele não funcionar? 
  
  Sendo D o evento em que o circuito é defeituoso e A, B, C os eventos de cada fábrica, sabemos que 
    \[
      \mathbb{P}(A) = 0,40,\quad \mathbb{P}(B) = 0,30,\quad \mathbb{P}(C) = 0,30.
    \]
    Além disso, sabemos que 
    \[
      \mathbb{P}(D|A) = 0,02,\quad \mathbb{P}(D|B) = 0,04,\quad \& \mathbb{P}(D|C) = 0,03
    \]
    Segue do teorema que 
      \[
        \mathbb{P}(D) = \sum\limits_{i=1}^{n}\mathbb{P}(D|A_{i})\mathbb{P}(A_{i}) = 0,025.
      \]

    Determine a probabilidade do defeituoso ter sido produzido pela empresa A. 
      \[
        \mathbb{P}(A|D) = \frac{\mathbb{P}(A\cap D)}{\mathbb{P}(D)} = \frac{\mathbb{P}(D|A)\mathbb{P}(A)}{\mathbb{P}(D)} = \frac{0,01\times 0,4}{0,025} = \frac{0,004}{0,025} = 0,16.
      \]
\end{example}
\newpage

\section{Aula 04 - 07/09/2023}
\subsection{Motivações}
\begin{itemize}
  \item Noções de Contagens e resultados iniciais;
  \item Princípio Fundamental da Contagem;
  \item Permutações, Arranjos e Combinações.
\end{itemize}
\subsection{Introdução}
  Começamos com o seguinte problema de motivação: Em um lote de 100 peças, das quais
20 são defeituosas e 80 são perfeitas, escolhe-se ao acaso dez dessas peças, sem reposição.
Qual é a probabilidade de que \textit{exatamente} metade das peças escolhidas seja defeituosa?

  A análise deste problema começa a partir do espaço amostral, \(\Omega \), em que cada elemento
é constituído de dez possíveis peças do lote, sejam elas \((a_{1}, \cdots, a_{10})\). Quantos resultados
desses existem? Dentre esses resultados, quais deles têm a característica desejada - exatamente metade das
peças selecionadas são defeituosas?

  Problemas do tipo são comuns no mundo, então foram desenvolvidas ferramentas adequadas para tratar deles, as chamadas
\textit{técnicas sistemáticas de enumeração}. Vamos conhecer algumas delas.
\subsection{Princípios Fundamentais da Contagem}
  Suponha que um processo \(P_{1}\) possa ser executado de \(n\) maneiras diferentes e considere,
também, que um segundo processo, \(P_{2}\), possa ser executado de m maneiras. Partindo da hipótese de que
cada maneira de executar \(P_{1}\) possa ser seguida por uma outra para executar \(P_{2},\) o processo
``\(P_{1}\) seguido de \(P_{2}\)'', denotado por P, pode ser executado de \(n=n \cdot m\) maneiras. Essa versão é 
a mais básica do \textit{princípio fundamental da contagem para a multiplicação}. Formalmente,
\begin{theorem*}
  Se existirem k processos e o i-ésimo puder ser executado de \(n_{i}\) maneiras, \(i=1, 2, \cdots, \), então
o procedimento P formado por \(P_{1},\) seguido por \(P_{2}\), seguido por \(P_{3}, \cdots,\) seguido pelo procedimento \(P_{k}\),
poderá ser executado de 
  \[
    n = n_{1}\times n_{2}\times \cdots\times n_{k}
  \]
  maneiras.
\end{theorem*}
\begin{example}
  Uma peça manufaturada deve passar por três estações de controle. Em cada estação, a peça é
infecionada para determinada característica e marcada adequadamente. Na primeira estação, três
classificações são possíveis, enquanto que nas duas últimas, quatro classificações são possíveis. 
De quantas maneiras possíveis uma peça pode ser marcada?

  Utilizando o princípio fundamental da contagem, segue que cada peça pode ser marcada de \(3\times 4\times 4 = 48\) maneiras.
\end{example}
  Além da versão de multiplicação, há uma para a adição, relacionada ao termo ``realizar um OU outro''.
Indo direto ao ponto, ele pode ser enunciado da seguinte forma:
\begin{theorem*}
  O \textit{princípio fundamental da contagem para a adição} afirma que, se existem k processos
e o i-ésimo procedimento puder ser realizado de \(n_{i}, i = 1, 2, \cdots, k\) maneiras, então
o número de maneiras pelas quais podemos realizar ou o processo \(P_1\), ou o processo \(P_{2}\),
 \(\cdots,\) ou o processo \(P_{k}\), é dado por 
   \[
     n = n_1 + n_{2} + \cdots + n_{k},
   \]
  em que supõe-se que dois processos quaisquer não podem ser realizados simultaneamente.
\end{theorem*}
\begin{example}
  Suponha que estejamos planejando uma viagem e devamos escolher entre o transporte por ônibus ou por trem.
Se existirem três rodovias e duas ferrovias, quantos caminhos estão disponíveis para a viagem?

  Como não é possível andar de ônibus e trem ao mesmo tempo, aplicamos o princípio fundamental da contagem para a adição.
Portanto, existirão 3 + 2 = 5 caminhos disponíveis para a viagem.
\end{example}
\subsection{Permutações, Arranjos e Combinações}
  Suponha que tenhamos n objetos diferentes. De quantas maneiras, \(_{n}P_{n}\), podemos dispor esses objetos?
Vejamos um exemplo:
\begin{example}
  Se tivermos os objetos a, b e c, poderemos considerar as seguintes permutações: 
    \[
      abc, acb, bac, bca, cab\quad\text{e}\quad cba.
    \]
    Portanto, a resposta é 6.
\end{example}
  Utilizando o princípio fundamental da contagem para a multiplicação, o número de permutações
de n objetos diferentes é dado por 
  \[
    _{n}P_{n} = n\times(n-1)\times(n-2)\times \cdots\times 1 = n!.
  \]
  Outras noções importantes são de arranjos e de combinações. Consideremos n objetos diferentes. Desejamos 
escolher r desses objetos, sendo r um número \(0\leq r\leq n\) e permutar os r
escolhidos. Denotamos por \(_{n}A_{r}\) o número de maneiras de fazer esses arranjos.
Como paramos no \((n-r+1)\)-ésimo elemento, o princípio fundamental da contagem para a multiplicação mostra que 
  \[
    _{n}A_{r} = n\times(n-1)\times(n-2)\times \cdots\times(n-r+1) = \frac{n!}{(n-r)!}
  \]
 \begin{example}
   Temos os objetos a, b, c e d, e \(r=2\). Desejamos contar 
   \[
     ab, ac, ad, bc, bd\quad\text{e}\quad cd,
   \]
  mas, como ab e ba são os mesmos objetos com a ordem inversa, não escreveremos eles. Assim, 
  \[
    _{4}A_{2} = \frac{4!}{2!} = \frac{24}{2} = 12.
  \]
 \end{example}
  Para obtermos o resultado geral, considere a expressão para o arranjo dos r objetos dentre n, ou seja, 
  \[
    _{n}A_{r} = \frac{n!}{(n-r)!}.
  \]
  Considerando \(_{n}C_{r}\) como o número de maneiras de escolher r objetos dentre os n, mas 
sem considerar a ordem. Uma vez que r objetos tenham sido escolhidos, existirão \(r!\) maneiras
de permutá-los. Consequentemente, outra aplicação do princípio fundamental da contagem para a multiplicação 
fornece-nos 
  \[
    _{n}C_{r}\times r! = \frac{n!}{(n-r)!}.
  \]
  Portanto, o número de maneiras de escolher r dentre n objetos diferentes, desconsiderando
a ordem deles, é dado por 
  \[
    _{n}C_{r} = \frac{n!}{r!(n-r)!} = \binom{n}{r}.
  \]
  Algumas propriedades dos números \(\binom{n}{r}\) valem ser mencionadas.
 \begin{prop*}
   Os números \(\binom{n}{r}\) apresentam as seguintes propriedades:
  \begin{itemize}
    \item[i)]   
  \[
    \binom{n}{r} = \binom{n}{n-r}.
  \]
    \item[ii)] 
      \[
        \binom{n}{r} = \binom{n-1}{r-1} + \binom{n-1}{r}.
      \]
  \end{itemize}
 \end{prop*}
\begin{proof*}
  i) Quando escolhemos r dentre n coisas, estamos ao mesmo tempo deixando (n-r) coisas não escolhidas e, por isso
escolher r dentre n é equivalente a escolher (n-r) dentre n. Em outras palavras, 

  ii) Fixe um elemento qualquer dos n objetos, digamos a. Ao escolher r objetos, a estará incluído ou excluído entre eles,
mas nunca poderá estar e não estar ao mesmo tempo. Logo, ao contar o número de maneiras de escolher r objetos,
aplicamos o princípio fundamental da contagem para a adição. 

  Se a for excluindo, escolhemos os r objetos dentre os (n-1) restantes, e existem \(\binom{n-1}{r}\) maneiras de fazer isso. 

  Caso a seja incluso, somente (r-1) objetos devem ser escolhidos dentre os (n-1) restantes, resultando em \(\binom{n-1}{r-1}.\)

  Portanto, 
    \[
      \binom{n}{r} = \binom{n-1}{r-1} + \binom{n-1}{r}.\text{\qedsymbol}
    \]
\end{proof*}
\begin{example}
  Considerando oito pessoas, quantas comissões de três membros podem ser escohidas?

  Desde que duas comissões sejam a mesma comissão se forem constituídas pelas mesmas pessoas
(não se levando em conta a ordem em que sejam escolhidas), teremos quantas comissões possíveis? 
  \[
    _{8}C_{3} = \binom{8}{3} = \frac{8!}{3!(8-3)!} = \frac{40320}{6\times 120} = 56.
  \]
\end{example}
\begin{example}
  Com oito bandeiras diferentes, quantos sinais, feitos com três bandeiras podemos obter?

  Este problema é próximo do anterior, entretanto, aqui a ordem acarreta diferença e, por isso, obteremos quantos sinais?

  Teremos que utilizar o arranjo ao invés da combinação, tal que 
  \[
    _{8}A_{3} = \frac{8!}{(8-3)!} = 336.
  \]
\end{example}
\begin{example}
  Voltemos à pergunta inicial sobre o lote. Temos nele 20 peças defeituosas e 80 peças perfeitas. Ao escolher
10 peças ao acaso, sem reposição, nos perguntamos - qual é a probabilidade de escolhermos exatamente 5 peças defeituosas
e 5 peças perfeitas entre as 10 escolhidas?

  Primeiro, enumeramos o número de maneiras que podemos amostrar as peças dentre as 100, isto é, 
  \[
    _{100}C_{10} = \binom{100}{10}.
  \]
  Em seguida, enumeramos o número de maneiras que podemos amostrar as 5 peças defeituosas dentre as 20 totais, ou seja 
  \[
    _{20}C_{5} = \binom{20}{5},
  \]
e, também, o número de maneiras que podemos amostrar as 5 peças perfeitas entre as 80,
  \[
    _{80}C_{5} = \binom{80}{5}.
  \]
  Com isso, a probabilidade desejada é dada por 
  \[
    \frac{\binom{20}{5}\binom{80}{5}}{\binom{100}{10}} \approx 0,021 = 2,1\%
  \]
\end{example}
  A ideia deste exemplo pode ser generalizada da seguinte forma: dados N objetos, dos quais
n são escolhidos ao acaso sem reposição, 
\begin{itemize}
  \item[a)] Teremos \(\binom{N}{n}\) diferentes amostras possíveis;
  \item[b)] Se as N peças forem formadas por \(r_{1}\) da classe A e \(r_{2}\) da classe B (com \(r_{1} + r_{2} = N\).
\end{itemize}
  Então, a probabilidade de que as n peças escolhidos sejam exatamente \(s_{1}\) da classe A
e \((n-s_{1})\) da classe B será dada por 
  \[
  \frac{\binom{r_{1}}{s_{1}}\binom{r_{2}}{n-s_{1}}}{\binom{N}{n}}.
  \]
  Essa expressão denomina-se \textbf{probabilidade hipergeométrica}.

  Em todas as técnicas vistas até agora, supomos que os objetos sejam diferentes entre si, mas isso nem sempre é possível.
Forneceremos a ferramenta que permite lidar com isso agora. 

Suponha que temos n objetos, subdivididos em k grupos com
 \(n_{1}, n_{2}, \cdots, n_{k}\) elementos indistinguíveis entre si, dentro de seus respectivos grupos, 
 e tais que \(n = n_{1} + n_{2} + \cdots + n_{k}\). Neste caso, o número de permutações possíveis desses n objetos é 
 \[
   \frac{_{n}P_{n}}{_{n_{1}}P_{n_{1}}\times _{n_{2}}P_{n_{2}}\times \cdots _{n_{k}}P_{n_{k}}} = \frac{n!}{n_{1}!\times n_{2}!\times \cdots\times n_{k}!}
 \]
 Note que, se todos os objetos fossem diferentes, \(n_{i} = 1\) para todo \(i=1, 2, \cdots, k\) e, consequentemente,
a fórmula seria reduzida ao caso que vimos antes, ou seja, \(n!.\)

\newpage

\section{Aula 05 - 19/09/2023}
\subsection{Motivações}
\begin{itemize}
  \item Variáveis Aleatórias;
  \item Distribuições discretas;
  \item Massa de probabilidade.
\end{itemize}
\subsection{Observação}
  A aula 04 foi, na verdade, uma aula sobre contabilidade, que irei adicionar futuramente, pois não consegui copiar ela na hora.
\subsection{Variáveis aleatórias}
  Na descrição de um experimento aleatório, é conveniente descrever numericamente os resultados.
Vimos, ao longo do curso, exemplos de experimentos que já vinham atrelados a números - o tempo de duração
de uma lâmpada, um número telefônico que chega a uma central, até mesmo os dados e suas faces. No entanto,
em várias situações, esse tipo de informação não está disponível. Também tivemos exemplos
dessas situações, tais quais o sexo de um filho que nasceu e o resultado do lançamento de duas moedas.
Para estes casos, como podemos lidar com eles numericamente? Uma forma natural de fazer
isso é contar quantas vezes uma coisa aparece.
\begin{example}
  Considere uma moeda lançada duas vezes. Seja X a função definida no espaço e que é
igual ao número de caras nos lançamentos. Vale que:
\begin{center}
  \begin{table*}[h!]
  \caption{Variável Aleatória de Caras}
  \centering
    \begin{tabular}{| c | c |}
      \hline
      Espaço amostral & Valores de X\\
      \hline
      C C & 2\\
      C \(\overline{C}\) & 1\\
      \(\overline{C}\) C & 1\\
      \(\overline{C}\) \(\overline{C}\) & 0\\
      \hline
    \end{tabular}
  \end{table*}
\end{center}
  Observa-se desta tabela que a variável aleatória associada ao evento ``moeda caiu cara" assume os valores
 \(X(CC) = 2, X(C\overline{C})=1, X(\overline{C}C)=1), X(\overline{CC}) = 0.\)
\end{example}
\begin{example}
  Dado um lote de 4 peças, das quais 2 são defeituosas, retiram-se peças até que as duas defeituosas
sejam retiradas. Coloque como X o número de peças retiradas. Temos:
\begin{center}
  \begin{table}[h]
  \caption{Número de Peças Retiradas}
  \centering
    \begin{tabular}{| c | c |}
      \hline
      Espaço Amostral & Valores de X\\
      \hline
      D D & X(D, D) = 2\\
      D P D & X(D, P, D) = 3\\
      P D D & X (P, D, D) = 3\\
      P P D D & X(P, P, D, D) = 4\\
      P D P D & X(P, D, P, D) = 4\\
      D P P D & X(D, P, P, D) = 4\\
      \hline
    \end{tabular}
  \end{table}
\end{center}
\end{example}
  Em outras palavras, é interessante associar, a cada ponto do espaço amostral, um número real. Essa associação é
chamada \textit{variável aleatória}. Formalmente, podemos escrever a seguinte definição:
\begin{def*}
  Uma variável aleatória é uma função \(X:\Omega \rightarrow \mathbb{R}\) definida num espaço amostral e que assume valores reais.
Sua imagem será denotada por \(R_{X}\). \(\square\)
\end{def*}
  Também é importante transmitir a noção de finitude, ou de quantidades não contínuas de valores.
 \begin{def*}
   As variáveis aleatórias que assumem valores em um conjunto enumerável serão denominadas discretas. Variáveis aleatórias que assumem valores
num intervalo da reta real serão denominadas contínuas.\(\square\)
 \end{def*}
  Os eventos associados a \(\Omega \) são ``relacionados'' a eventos associados com \(R_{X}\) a partir 
da seguinte definição:
\begin{def*}
  Seja o espaço amostral \(\Omega \). Seja X uma variável aleatória com imagem \(R_{X}\). Tome A
um evento em \(\Omega \) e B um evento em \(R_{X}\). Diremos que os eventos A e B são equivalentes se 
  \[
    A = \{\omega \in \Omega : X(\omega )\in B\}.\quad\square
  \]
\end{def*}
\begin{def*}
  Seja A um evento em \(\Omega \) e B um evento em \(R_{X}\). Definimos a probabilidade de B como
 \(\mathbb{P}_{X}(B) = \mathbb{P}(A),\) em que \(A = \{\omega \in \Omega : X(\omega )\in B\}.\quad\square\)
\end{def*}
  Denotaremos por \(\mathbb{P}_{X}\) a medida de probabilidade induzida por X em \(R_{X}\), tal que \((R_{X}, \cdot , \mathbb{P}_{X})\) será o espaço
de probabilidade induzido pela variável aleatória.
\subsection{Distribuição de Probabilidade}
  Vamos nos restringir às variáveis aleatórias discretas. Para conhecermos uma variável aleatória,
além de seus valores, precisamos ter em mente as probabilidades associadas a elas. Nisto, entra a ideia
de distribuição de probabilidade.
\begin{def*}
  A distribuição de probabilidade de uma variável aleatória discreta X, definida em um espaço amostral S,
é uma tabela que associa a cada valor de X sua probabilidade. Em outras palavras, 
  \[
    F(x) = \mathbb{P}(X\in (-\infty, x]) = \mathbb{P}(X\leq x),
  \]
  em que x percorre todos os reais.\(\square\)
\end{def*}
\begin{example}
  Vamos olhar para a distribuição de probabilidade da variável aleatória do caso das moedas.
Para cada valor de X, determinamos os pontos amostrais nos quais X é igual a tal valor, ou seja,
a imagem inversa de X. Vamos observar na tabela:
\begin{center}
  \begin{table}[h]
  \caption{Valores de X, probabilidades e pontos amostrais}

  \centering
    \begin{tabular}{| c | c | c |}
      \hline
      Valores de X & Pontos Amostrais & Probabilidades\\
      \hline
      0 & \(\overline{C}\overline{C}\) & \(\frac{1}{4}\)\\
      1 & \(\overline{C}C, C\overline{C}\) & \(\frac{1}{2} = \frac{1}{4} + \frac{1}{4}\)\\
      2 & CC & \(\frac{1}{4}\)\\
      \hline
    \end{tabular}
  \end{table}
\end{center}
  Os valores das probabilidades são calculados da seguinte forma:
 \begin{align*}
   &\mathbb{P}[X = 0] = \mathbb{P}(\overline{CC}) = \frac{1}{4}\\
   &\mathbb{P}[X = 1] = \mathbb{P}(\overline{C}C) = \frac{1}{2}\\
   &\mathbb{P}[X = 2] = \mathbb{P}(CC) = \frac{1}{4}.
 \end{align*}
\end{example}
\begin{example}
  Consideremos o experimento de lançar um dado sucessivamente sobre uma superfície plana. 
Analisemos quantos lançamentos o número 6 ocorre pela primeira vez - evento que denotaremos por X.
Temos, para todo \(n\geq 1\), 
  \[
    \mathbb{P}(X = n) = \biggl(\frac{5}{6}\biggr)^{(n-1)}\frac{1}{6}.
  \]
  De fato, pelos lançamentos serem independentes, a probabilidade de que não ocorra 6 nos
(n-1) primeiros lançamentos, mas que ocorra no n-ésimo lançamento, é dada pela fórmula dada acima.
\end{example}
\begin{lemma*}
  A função de distribuição de uma variável aleatória X satisfaz as seguintes condições:
 \begin{itemize}
   \item[a)] \(0\leq F(x)\leq 1\)
   \item[b)] F(x) é não decrescente e é contínua à direita
   \item[c)] \(\lim_{x\to \infty}F(x) = 0\) e \(\lim_{x\to \infty}F(x) = 1.\)
 \end{itemize}
\end{lemma*}
\begin{proof*}
  Isso será, essencialmente, um comentário sobre a ideia da prova.

  a) Segue de que F(x) representa uma probabilidade, ou seja, \(0\leq F(x)\leq 1.\)

  b) Se \(x_{1}\leq x_{2},\) então \(\{\omega \in \Omega : X(\omega ) < x_{1}\}\subseteq{\{\omega \in \Omega : X(\omega )\leq x_{2}\}}\) e, assim, \(\mathbb{P}(\{\omega \in \Omega : X(\omega )[2]\leq x_{1}\})\leq 
  \mathbb{P}(\omega \in \Omega : X(\omega )\leq x_{2}),\) ou seja, \(F(x_{1})\leq F(x_{2}).\)

  Para provar a continuidade à direita, seria preciso o seguinte resultado que sai do escopo do curso:
 \begin{quote}
   ``Se uma sequência de eventos \(A_{n}\) é decrescente e se aproxima de um evento A, então a sequência
   das probabilidades \(\mathbb{P}(A_{n})\) também é decrescente e tem limite \(\mathbb{P}(A).\)''
 \end{quote}
 Assumindo esse resultado, consideramos uma sequência \(\{x_{n}\}\) de números reais que seja decrescente e que
 \(\lim_{n\to \infty}x_{n} = x.\)  Assim, a sequência de eventos \([X\leq x_{n}]\) é decrescente e se aproxima de \([X\leq x].\) 
 Pela propriedade que citada, segue a continuidade à direita.

 c) Para uma sequência de eventos \(A_{n}\) que cresce para um evento A, vale uma propriedade análoga - 
\(\mathbb{P}(A_{n})\) converge para \(\mathbb{P}(A)\). Assim, tome \(\{x_{n}\}\) uma sequência de números reais
que tende a infinito. Assim, \([X\leq x_{n}]\) é uma sequência que tende ao evento \([X < \infty]\), tal que \(\mathbb{P}[X\leq x_{n}]\) 
converge para \(\mathbb{P}[X <\infty]\), que é trivialmente o espaço todo, cuja probabilidade é 1. Para demonstrar a segunda parte,
considera-se uma sequência \(\{x_{n}\}\) que tende a \(-\infty\), ou seja, \([X\leq x_{n}]\) tende ao vazio \(\emptyset\) e, portanto,
 \(F(x_{n}) = \mathbb{P}[X\leq x_{n}].\) \qedsymbol
\end{proof*}
\begin{example}
Seja 
  \[
    F(x)  = \left\{\begin{array}{ll}
        0,\quad x < 0;\\
        \frac{1}{2},\quad 0\leq x < 1;\\
        1,\quad x\geq 1.
      \end{array}\right.
  \]
  Essa F é uma função de distribuição?

  Ela é, de fato. Para ver isso, note que, como \(F(x) = 0\) para \(x < 0\) e \(F(x) = 1\) para 
 \(x\geq 1\),
  \[
    \lim_{x\to -\infty} F(x) = 0\quad\&\quad \lim_{x\to +\infty}F(x) = 1
  \]
  Além disso, a continuidade nos reais entre 0 e 1 é simples. Para os extremos, temos 
    \[
      F(0) = \lim_{x\to 0^{+}}F(x) = \frac{1}{2}\quad\&\quad F(1) = \lim_{x\to 1^{+}}F(x) = 1.
    \]
  Por fim, F é não decrescente pela sua definição.  
\end{example}
\begin{def*}
  A função de probabilidade de uma variável aleatória discreta X é uma que atribui probabilidade
a cada um dos possíveis valores \(x_{i}\) assumidos pela variável aleatória X, isto é, 
  \[
    p(x_{i}) = \mathbb{P}(X = x_{i}) = \mathbb{P}(\{\omega \in \Omega (\omega ): X(\omega ) = x_{i}\}),\quad i = 1, 2, \cdots, n.
  \]
  Além disso, \(p(x_{i})\) deve satisfazer 
    \[
      0\leq p(x_{i})\leq 1,\quad i = 1, \cdots, n
    \]
  e 
    \[
      \sum\limits_{i=1}^{n}p(x_{i}) = 1.\quad \square
    \]
\end{def*}

\subsection{EXTRA: Densidade de Probabilidade}
  As densidades de probabilidade surgem para tratar das variáveis aleatórias contínuas. Um dos problemas 
que surgem é que a soma dos valores em quantidades não enumeráveis de números positivos não pode ser igual a um.
  Com isso, definimos a densidade de probabilidade como uma função não negativa tal que sua integral, avaliada
num dado intervalo, equivale à probabilidade da variável pertencer a este intervalo. Além disso, para ser condizente com
a probabilidade total ser 1, impõe-se que a integral estendida à reta toda seja um.
\begin{def*}
  A densidade de probabilidade de uma variável aleatória contínua é uma função \(f(x)\geq 0\) tal que 
    \[
      \int_{-\infty}^{+\infty}f(x)dx = 1.
    \]
Além disso, a probabilidade de uma variável aleatória X pertencer a um intervalo da forma \((a, b]\) é dada por 
  \[
    \mathbb{P}[a < X\leq b] = \int_{a}^{b}f(x)dx.\quad \square
  \]
\end{def*}
\begin{example}
  Seja \(f(x) = x\) para \(0\leq x\leq 1\) e \(f(x) = 2 - x\) para \(1\leq x\leq 2\). No complementar desses dois,
coloque \(f(x)=0.\) Note que 
  \[
    \int_{0}^{2}f(x)dx = \int_{0}^{1}xdx + \int_{1}^{2}2-xdx = 1.
  \]
  Vamos calcular, também, as probabilidades \(\mathbb{P}[0\leq X\leq 0.8].\) Segue que 
    \[
      \mathbb{P}[0\leq X\leq 0.8]=\int_{0}^{0.8}xdx = \frac{1}{2}x^{2}\biggl|_{0}^{0.8}\biggr. = \frac{1}{2}(0.8)^{2} = 0.32.
    \]
  e 
    \[
      \mathbb{P}[0.3\leq X\leq 1.5] = \int_{0.3}^{1}xdx + \int_{1}^{1.5}2-xdx = 0.83.
    \]
\end{example}
\newpage

\section{Aula 06 - 10/10/2023}
\subsection{Motivações}
\begin{itemize}
  \item Esperança
\end{itemize}
\subsection{Esperança Discreta}
  A esperança matemática, ou apenas esperança, é uma quantidade associada às variáveis aleatórias e que representa,
por exemplo, a média dos valores do resultado de um experimento repetido uma sequência muito grande de vezes, sempre com
respeito aos extremos do intervalo. É um conceito essencial para estudar futuramente a noção de momento, de variância e de desvio padrão.
Sem mais delongas, formalizaremos a seguir as bases dessa ideia, juntamente de exemplos de como calculá-la.
  
\begin{def*}
  A esperança de uma variável aleatória discreta X, definida num espaço amostral \(\Omega \) no qual está definida uma
probabilidade \(\mathbb{P},\) é definida por 
  \[
    \mathbb{E}(X) = \sum\limits_{\omega \in \Omega }^{}X(\omega )\mathbb{P}(\omega ),
  \]
desde que \(\sum\limits_{\omega \in \Omega }^{}|X(\omega )|\mathbb{P}(\omega ) < \infty. \square\)
\end{def*}
  Um resultado interessante é que a esperança pode ser expressa por meio da função de distribuição previamente vista:
\begin{lemma*}
  A esperança matemática de uma variável aleatória discreta X que assume os valores \(x_{i}\) para \(i = 1, 2, \cdots\), com
respectivas probabilidades \(\mathbb{P}[X=x_{i}],\) é dada por 
  \[
    \mathbb{E}(X) = \sum\limits_{i=1}^{\infty}x_{i}\mathbb{P}[X=x_{i}].
  \]
\end{lemma*}
\begin{proof*}
  A ideia dessa prova é, a partir da definição da esperança, obtermos a expressão desejada e vice-versa.
Denote os pontos do espaço amostral por \(\omega_{j}, j=1, 2, \cdots\). Partindo do ponto de que a série 
 \(\sum\limits_{i=1}^{n}X(\omega_{j})\mathbb{P}(\omega_{j})\) é absolutamente convergente, um teorema de análise
 matemática afirma que podemos reordenar seus termos como quisermos. Faremos isso da seguinte forma:
\begin{align*}
  \mathbb{E}(X) &= \color{blue}\sum\limits_{j=1}^{\infty}X(\omega_{j})\mathbb{P}(\omega_{j}) = \color{red}\sum\limits_{i=1}^{\infty}\biggl[\sum\limits_{j:X(\omega_{j})=x_{i}}^{}X(\omega_{j})\mathbb{P}(X(\omega_{j}))\biggr]\\
                &= \color{green}\sum\limits_{i=1}^{\infty}\biggl[\sum\limits_{j:X(\omega_{j}) = x_{i}}^{}x_{i}\mathbb{P}(X(\omega_{j}))\biggr]=\sum\limits_{i=1}^{\infty}\biggl[x_{i}\sum\limits_{j:X(\omega_{j})=x_{i}}^{}\mathbb{P}(X(\omega_{j}))\biggr]\\
                &= \color{magenta}\sum\limits_{i=1}^{\infty}x_{i}\mathbb{P}[X = x_{i}].
\end{align*}
  Vamos entender o que aconteceu por partes. Para facilitar a compreensão, há um guia por cor a seguir:
 \begin{itemize}
   \item[\textbf{Azul)}] Neste passo, escrevemos a definição da esperança.
   \item[\textbf{Vermelho)}] Utilizamos a convergência absoluta da série (\(\sum\limits_{\omega \in \Omega }^{}|X(\omega )|\mathbb{P}(\omega ) < \infty\) por definição) para
fazer a seguinte reordenação: Somamos primeiramente os termos nos quais a variável aleatória, quando calculada em \(\omega_{j}\), vale \(x_{i}\). Isso resulta na mudança de índice de j
para i, ou seja, após essa primeira soma, realizamos uma soma infinita em i ao invés de j.
   \item[\textbf{Verde)}] Como os termos selecionados são os que \(X(\omega_{j})\) vale \(x_{i}\), trocamos a expressão \(X(\omega_{j})\mathbb{P}(X(\omega_{j}))\) por
 \(x_{i}\mathbb{P}(X(\omega_{j}))\) primeiro, fazendo com que \(x_{i}\) perca a dependência no índice j e possa ser retirado da primeira soma. Um processo similar será aplicado em
 \(\mathbb{P}(X(\omega_{j})),\) que é o próximo e último passo.
   \item[\textbf{Magenta)}] Por estarmos considerando os termos onde\(X(\omega_{j})\) vale \(x_{i}\), trocamos a expressão \(\mathbb{P}(X(\omega_{j}))\) por \(\mathbb{P}(X = x_{i})\), 
obtendo justamente a expressão do enunciado.
 \end{itemize}
 Como foi mencionado previamente, basta fazer o caminho oposto, partindo de \(\mathbb{E}(X) = \sum\limits_{i=1}^{\infty}x_{i}\mathbb{P}[X=x_{i}]\) e, a partir de 
 reordenações, chegar em \(\sum\limits_{j=1}^{\infty}X(\omega_{j})\mathbb{P}(X(\omega_{j})) = \sum\limits_{\omega \in \Omega }^{}X(\omega )\mathbb{P}(\omega ).\) \qedsymbol
\end{proof*}
  Outra propriedade muito importante tanto da esperança quanto das variáveis aleatórias é a linearidade. Não provaremos ela para
as variáveis aleatórias, mas isso quer dizer que, para variáveis aleatórias X e Y, vale para qualquer \(\Omega \ni \omega \)
  \[
    (X+Y)(\omega ) = X(\omega ) + Y(\omega )\quad\text{e}\quad (cX)(\omega ) = cX(\omega ).
  \]
  Precisamos disto para provas a mesma cosia para a esperança. De fato, 
 \begin{lemma*}
   Se as esperanças das variáveis aleatórias X e Y existem, então existe a esperança de X + Y. Além disso, se c é uma constante, temos
  \begin{itemize}
    \item[i)]\(\mathbb{E}(X+Y) = \mathbb{E}(X)+\mathbb{E}(Y)\);
    \item[ii)] \(\mathbb{E}(cX) = c \mathbb{E}(X).\)
  \end{itemize}
 \end{lemma*}
 \begin{proof*}
   Começamos mostrando que \(\mathbb{E}(X+Y)\) existe. Isso baseia-se nas propriedades de somas infinitas e módulo. De fato, 
     \[
       \mathbb{E}(X+Y) = \sum\limits_{\omega \in \Omega }^{}(X+Y)(\omega)\mathbb{P}(\omega) = \sum\limits_{\omega\in \Omega}^{}(X(\omega)+Y(\omega ))\mathbb{P}(\omega).
     \]
Assim, para que \(\mathbb{E}(X+Y)\) existe, é preciso que essa série seja finita em módulo. De fato, 
  \[
    \sum\limits_{\omega \in \Omega }^{}|X(\omega)+Y(\omega )|\mathbb{P}(\omega )\leq \sum\limits_{\omega \in \Omega }^{}(|X(\omega )| + |Y(\omega )|)\mathbb{P}(\omega ) = \sum\limits_{\omega \in \Omega }^{}|X(\omega )|\mathbb{P}(\omega ) + \sum\limits_{\omega \in \Omega }^{}|Y(\omega )|\mathbb{P}(\omega ).
  \]
Note que, como \(\mathbb{E}(X)\) e \(\mathbb{E}(Y)\) existem por hipótese, \(\sum\limits_{\omega \in \Omega }^{}|X(\omega )|\mathbb{P}(\omega ) < \infty\) e \(\sum\limits_{\omega \in \Omega }^{}|Y(\omega )|\mathbb{P}(\omega ) < \infty\), ou seja, 
  \[
    \sum\limits_{\omega \in \Omega }^{}|X(\omega)+Y(\omega )|\mathbb{P}(\omega )\leq \sum\limits_{\omega \in \Omega }^{}(|X(\omega )| + |Y(\omega )|)\mathbb{P}(\omega ) = \sum\limits_{\omega \in \Omega }^{}|X(\omega )|\mathbb{P}(\omega ) + \sum\limits_{\omega \in \Omega }^{}|Y(\omega )|\mathbb{P}(\omega ) < \infty.
  \]
Logo, \(\mathbb{E}(X+Y)\) existe. Além disso, segue da primeira expressão, isto é, 
  \[
   \mathbb{E}(X+Y) = \sum\limits_{\omega \in \Omega }^{}(X+Y)(\omega)\mathbb{P}(\omega) = \sum\limits_{\omega\in \Omega}^{}(X(\omega)+Y(\omega ))\mathbb{P}(\omega),
  \]
  que basta quebrar a série em duas para obter a expressão (i):
    \[
     \mathbb{E}(X+Y) = \sum\limits_{\omega\in \Omega}^{}(X(\omega)+Y(\omega ))\mathbb{P}(\omega) = \sum\limits_{\omega \in \Omega }^{}X(\omega )\mathbb{P}(\omega ) + \sum\limits_{\omega \in \Omega }^{}Y(\omega )\mathbb{P}(\omega ) = \mathbb{E}(X) + \mathbb{E}(Y),
    \]
  como queríamos. Por fim, tome c uma constante real. Então, 
    \[
      \mathbb{E}(cX) = \sum\limits_{\omega \in \Omega }^{}(cX)(\omega )\mathbb{P}(\omega ) = \sum\limits_{\omega \in \Omega }^{}cX(\omega )\mathbb{P}(\omega ) = c \sum\limits_{\omega \in \Omega }^{}X(\omega )\mathbb{P}(\omega ).
    \]
  Portanto, \(\mathbb{E}(cx) = c \mathbb{E}(x)\). \qedsymbol
   \end{proof*}
   Vamos ver um exemplo antes de seguir para a esperança contínua. 
  \begin{example}
    Uma loteria vende 100 bilhetes, cada um valendo R\$ 1,20. O bilhete sorteado ganhará um prêmio de R\$100,00.
  Qual é a esperança de seu ganho se você comprar um bilhete?
    
    Vamos designar por X a variável aleatória que representa o ganho. Se seu bilhete estiver entre os 99 que não ganham,
você pagou 1,20, ou seja, X assume o valor -1,20 em \(\frac{99}{100} = 0.99\) dos casos. Caso tenha a sorte de comprar o 
bilhete sorteado, X assume o valor \(100,00 - 1,20 = 98,80\), o que ocorre em \(\frac{1}{100} = 0.01\) dos casos. Assim,
a esperança de ganho é dada por 
  \[
    \mathbb{E}(X) = -1,20\times 0,99 + 98,80\times 0.01 = -0,20
  \]
  Como a esperança representa uma ``média'' dos resultados, na versão do jogo da loteria, uma esperança negativa quer dizer que
haverá uma perda na maioria dos casos, ou seja, há uma tendência do jogador perder dinheiro a longo prazo.
  \end{example}
\subsection{Esperança Contínua}
  Como no cálculo, faremos a passagem de quantidades discretas somadas para quantidades contínuas integradas. Em outras palavras,
se a função de distribuição da variável aleatória X é contínua, a esperança será definida da seguinte forma:
\begin{def*}
  A esperança de uma variável aleatória X, com densidade de probabilidade f(x), será dada por 
    \[
      \mathbb{E}(X) = \int_{-\infty}^{\infty}xf(x)dx.
    \]
\end{def*}
  Como a integral, assim como a soma, é linear, o lema provado que mostra a linearidade da esperança discreta permanece verdadeiro no caso contínuo. Vejamos, agora,
um exemplo da esperança contínua
\begin{example}
  Calcule a esperança da variável aleatória X, cuja densidade de probabilidade é dada por 
  \[
    f(x) = \left\{\begin{array}{ll}
        2x,\quad 0\leq x\leq 0.5,\\
        -\frac{2}{3}x + \frac{4}{3},\quad 0.5\leq x\leq 2\\
        0,\quad \text{caso contrário}
      \end{array}\right.
  \]

  Pela definição que vimos, segue que 
  \[
     \mathbb{E}(X) = \int_{-\infty}^{\infty}xf(x)dx.
  \]
  Antes de fazer a conta, vamos ver os possíveis valores da integral de xf(x), com base na definição de f:
  \[
   \int_{-\infty}^{\infty}xf(x)dx = \left\{\begin{array}{ll}
       \int_{0}^{0.5}x(2x)dx,\quad 0\leq x\leq 0.5\\
       \int_{0.5}^{2}x \biggl(-\frac{2}{3}x + \frac{4}{3}\biggr)dx,\quad 0.5\leq x\leq 2\\
       \int_{-\infty}^{a}x\times 0dx, a < 0, \text{ ou } \int_{b}^{\infty}x\times 0dx, b > 2.
     \end{array}\right.
 \]
  Com base nisso, a esperança será dada pela soma dessas integrais: 
  \begin{align*}
    \mathbb{E}(x) &= \int_{-\infty}^{a}x\times 0dx + \int_{0}^{0.5}x(2x)dx + \int_{0.5}^{2}x \biggl(-\frac{2}{3}x + \frac{4}{3}\biggr)dx + \int_{b}^{\infty}x\times0dx \\
                  &= 0 + \int_{0}^{0.5}x(2x)dx + \int_{0.5}^{2}x \biggl(-\frac{2}{3}x + \frac{4}{3}\biggr)dx + 0 \\
                  &= \frac{2}{3}x^{3}\biggl|_{0}^{0.5}\biggr. + \biggl(-\frac{2}{3}\biggr)\frac{1}{3}x^{3}\biggl|_{0.5}^{2}\biggr. + \frac{4}{3}\frac{1}{2}x^{2}\biggl|_{0.5}^{2}\biggr.\\
                  &= \frac{1}{12} - \frac{63}{36} + \frac{2}{3}\biggl(4-\frac{1}{4}\biggr) = \frac{30}{36} = 0.8333\cdots,
  \end{align*}
  em que assume-se que \(a < 0\) e que \(b > 0.\)
\end{example}
\newpage

\section{Aula 07 - 17/10/2023}
\subsection{Motivações}
\begin{itemize}
  \item Trabalhando com Esperança;
  \item Introdução à Variância.
\end{itemize}
\subsection{Esperança}
  Antes de mais nada, afirmamos mais uma propriedade das esperanças
 \begin{lemma*}
   Sejam X e Y variáveis aleatórias independentes cujos valores esperados existam. Então, 
     \[
       \mathbb{E}(XY) = \mathbb{E}(X)\mathbb{E}(Y).
     \]
 \end{lemma*}
 \begin{proof*}
   Vamos provar o caso discreto. Sejam X, Y variáveis aleatórias independentes cujas esperanças são \(\mathbb{E}(X), \mathbb{E}(Y)\). Como elas são independentes,
   \(\mathbb{P}(X)\mathbb{P}(Y) = \mathbb{P}(X\cap Y)\), o que equivale a \(\mathbb{P}(X\setminus{Y}) = \mathbb{P}(X)\). Por definição, 
   \[
     \mathbb{E}(XY) = \sum\limits_{\omega \in \Omega }^{}(XY)(\omega )\mathbb{P}(\omega ) = \sum\limits_{\omega \in \Omega }^{}X(\omega)Y(\omega )\mathbb{P}(\omega )
   \]
   Utilizando o lema para expressá-la como a função de distribuição, sejam \(x_{i}, i=1, 2, \cdots\) os valores
com probabilidades \(\mathbb{P}[X = x_{i}]\) e \(y_{j}, j=1, 2, \cdots\) a mesma coisa com \(\mathbb{P}[Y=y_{j}]\) no lugar. Assim, 
  \[
    \mathbb{E}(XY) = \sum\limits_{i=1}^{\infty}\sum\limits_{j=1}^{\infty}x_{i}y_{j}\mathbb{P}[X=x_{i}\cap Y=y_{j}] = \sum\limits_{i=1}^{\infty}\sum\limits_{j=1}^{\infty}x_{i}y_{j}\mathbb{P}[X=x_{i}]\mathbb{P}[Y=y_{j}] = \sum\limits_{i=1}^{\infty}x_{i}\mathbb{P}[X=x_{i}]\sum\limits_{j=1}^{\infty}y_{j}\mathbb{P}[Y=y_{j}]
  \]
  Note que, utilizando o lema novamente, as expressões das esperanças de X e Y são exatamente 
    \[
      \sum\limits_{i=1}^{\infty}x_{i}\mathbb{P}[X=x_{i}]\quad\text{e}\quad \sum\limits_{j=1}^{\infty}y_{j}\mathbb{P}[Y=y_{j}],
    \]
ou seja, obtivemos que, portanto,
  \[
    \mathbb{E}(XY) = \mathbb{E}(X)\mathbb{E}(Y).\text{\qedsymbol}
  \]

 \end{proof*}
\begin{example}
  Considere a variável aleatória X que denota o tempo, em minutos, para o processamento de um produto. A função de probabilidade de X é 
 \begin{center}
   \begin{table}[h!]
   \centering
     \begin{tabular}{| c | c c c c c c |}
       \hline 
       \(x_{i}\) & 2 & 3 & 4 & 5 & 6 & 7\\
       \hline
       \(\mathbb{P}(X = x_{i})\) & 0.1 & 0.1 & 0.3 & 0.2 & 0.2 & 0.1\\
       \hline
     \end{tabular}
   \end{table}
 \end{center}
\begin{itemize}
  \item[a)] Calcule o valor de \(\mathbb{E}(X).\)
  \item[b)] Calcule o valor de \(\mathbb{E}(2 + X)\)
\end{itemize}
  
  a) Utilizando a fórmula para esperança discreta, temos 
    \[
      \mathbb{E}(X) = 2\times 0.1 + 3\times 0.1 + 4\times 0.3 + 5\times 0.2 + 6\times 0.2 + 7\times 0.1 = 0.2 + 0.3 + 1.2 + 1.0 + 1.2 + 0.7 = 4.6
    \]

  b) Como a esperança age de maneira linear, \(\mathbb{E}(2 + X) = 2 + \mathbb{E}(X).\) Calculamos \(\mathbb{E}(X)\) no item (a), tal que 
    \[
      \mathbb{E}(2+x) = 2 + 4.6 = 6.6
    \]
\end{example}
\begin{example}
  A demanda diária de um supermercado (em centenas de quilos) pode ser descrita pela variável aleatória X com função densidade 
    \[
      f(x) = \left\{\begin{array}{ll}
          \frac{2x}{3},\quad 0\leq x <1,\\
          \frac{-x}{3} + 1,\quad 1\leq x <3\\
          0,\quad \text{caso contrário}.
        \end{array}\right.
    \]
  Calcule \(\mathbb{E}(X).\)

  Utilizando a fórmula para a esperança contínua, 
    \[
      \mathbb{E}(X) = \int_{0}^{1}\frac{2x}{3}xdx + \int_{1}^{3}\biggl(\frac{-x}{3} + 1\biggr)xdx = \frac{2}{9} + \frac{10}{9} = \frac{12}{9} = \frac{4}{3} 
    \]
\end{example}
\begin{example}
  Uma máquina corta arames conforme um comprimento específico dado. Em virtude de certas imprecisões do mecanismo de corte, o comprimento
do arame cortado (em polegadas), X, pode ser considerado como uma variável aleatória uniformemente distribuída sobre \([11.5, 12.5].\) O
comprimento especificado é 12 polegadas.
\begin{itemize}
  \item Se \(11.7\leq X < 12.2\), pode-se vender com um lucro de US\$0.25;
  \item Se \(X\geq 12.2\), corta-se e vende-se com um lucro de US\$0.10;
  \item Se \(X < 11.7\), o arame é refugado e perde-se US\$ 0.02.
\end{itemize}
Como podemos entender o lucro total por pedaço de arame cortado?
  
  Para este exercício, coloquemos \(\mathbb{P}(X\leq x) = F(x) = \int_{-\infty}^{x}f(s)ds = \int_{11.5}^{x}1ds = x - 11.5\) se \(11.5 < s < 12.5\), sendo este o intervalo no qual
X é uma variável aleatória distribuída uniformemente. Com isso, coloque 
  \[
    Y \left\{\begin{array}{ll}
        -0.02,\quad \text{se está em prejuízo }(X < 11.7)\\
        0.25,\quad \text{se está no ideal }(11.7\leq X < 12.2\\
        0.1,\quad \text{se não há prejuízo nem é ideal }(x\geq 12.2).
      \end{array}\right.
  \]
  Com estas informações, temos 
  \[
    \mathbb{E}(Y) = -0.02\times \underbrace{F_{X}(11.7)}_{0.2} + 0.25\underbrace{(F_{X}(12.2)-F_{X}(11.7))}_{0.5} + 0.1\underbrace{(1-F_{X}(12.2))}_{0.3} = 0.151
  \]
\end{example}
\subsection{Variância}
  Suponha que, associada à variável aleatória X, temos \(\mathbb{E}(X) = 2\). O que exatamente isso significa? Afinal, é importante que, qualitativamente,
não atrelemos a isso um significado errado, seja isso exagerar ou diminuir a informação carregada.
\newpage

\section{Aula 08 - 19/10/2023}
\subsection{Motivações} 
\begin{itemize}
  \item Variância;
\end{itemize}
\subsection{Variância}
\paragraph{} Continuando do ponto de partida, buscamos responder o significado da frase ``Associada à variável
aleatória X, temos \(\mathbb{E}(X) = 2\).''

  Ao considerarmos uma quantidade muito grande de realizações de X, quando calcula-se a média desses valores,
eles estarão, em média, próximos a 2. No entanto, podem estar muito distantes dele.
\begin{example}
  Suponhamos que X represente a duração da vida de lâmpadas que estejam sendo recebidas de um fabricante e que \(\mathbb{E}(X) = 1000\)horas.
Isto pode significar uma dentre \textbf{muitas coisas}. Por exemplo, que algumas delas vão estar um pouco acima de \(1000\) horas,
ou um pouco abaixo, mas giram em torno disso. Por outro lado, pode ser que todas estejam muito acima de mil e muito abaixo de mil.
Esse tipo de informação não é possível obter apenas com base na esperança.
\end{example}
\begin{def*}
  A \textbf{mediana} é o ponto a partir do qual todos os valores podem ser separados em 50\% acima ou 50\% abaixo. A \textbf{moda} é
o argumento máximo da distribuição de probabilidade. Matematicamente, 
  \[
    \text{Med}(X) \coloneqq \biggl\{x: F(x) = \int_{-\infty}^{x}f(x)dx = \frac{1}{2}\biggr\} ,\quad Mo(x) \coloneqq \text{arg}\max{f(x)}
  \]
  A \textbf{variância} é definida como 
    \[
      Var(X)\coloneqq \mathbb{E}\biggl[(X-\mathbb{E}(x))^{2}\biggr] = \mathbb{E}(X^{2}) - [\mathbb{E}(X)]^{2},
    \]
  em que \(\mathbb{E}(X^{2}) = \sum\limits_{i=1}^{\infty}x_{i}^{2}p(x_{i})\) é chamado \textbf{segundo momento central}.
  O \textbf{desvio} é definido por \((X-\mathbb{E}(X))^{2}\). Além disso, definimos como \textbf{desvio padrão} a 
raiz da variância 
  \[
    DP(X) \coloneqq  \sqrt[]{Var(X)} = \mathbb{E}\biggl[|X-\mathbb{E}(X)|\biggr].\quad\square
  \]
\end{def*}
  No caso contínuo, a esperança assume a forma 
    \[
      Var(X) = \underbrace{\int_{-\infty}^{\infty}x^{2}f(x)dx}_{\mathbb{E}(X^{2})} - \underbrace{\biggl[\int_{-\infty}^{\infty}xf(x)dx\biggr]^{2}}_{[\mathbb{E}(X)]^{2}}
    \]
  Algumas propriedades da variância: 
 \begin{lemma*}
   Sejam X, \(X_{1}, \cdots, X_{n}\) variáveis aleatórias e c uma constante real. Então, 
  \begin{itemize}
    \item[a)] Var(c) = 0;
    \item[b)] Var(c+X) = Var(X);
    \item[c)] \(Var(cx) =c^{2}Var(x).\)
    \item[d)] Se \(X_{1}, X_{2}, \cdots, X_{n}\) são independentes, 
      \[
        Var(X_{1}+X_{2}+\cdots+X_{n}) = Var(X_{1})+Var(X_{2})+\cdots+Var(X_{n}).
      \]
  \end{itemize}
 \end{lemma*}
 \newpage
\begin{example}
  Considere a variável aleatória X, que denota o tempo em minutos para o processamento de um produto. A função de probabilidade de X é 

 \begin{center}
  \begin{table}[h!]
  \centering
    \begin{tabular}{| c | c c c c c c |}
      \hline 
      \(x_{i}\) & 2 & 3 & 4 & 5 & 6 & 7\\
      \hline
      \(\mathbb{P}(X = x_{i})\) & 0.1 & 0.1 & 0.3 & 0.2 & 0.2 & 0.1\\
      \hline
    \end{tabular}
  \end{table}
\end{center}

 a) Calcule \(Var(X)\) e \(DP(X)\), sabendo que \(\mathbb{E}(X) = 4.6.\)

 Como \(Var(X) = \mathbb{E}(X^{2}) - [\mathbb{E}(X)]^{2} = \mathbb{E}(X^{2}) - (4,6)^{2},\) podemos reescrever como 
 \begin{align*}
   Var(X) &= \sum\limits_{x=2}^{7}x^{2}\mathbb{P}(X=x) - (4,6)^{2} = 2^{2}\cdot 0,1 + 3^{2}\cdot 0,1 + 4^{2}\cdot 0,3 + 5^{2}\cdot 0,2 + 6^{2}\cdot 0,2 + 7^{2}\cdot 0,1 - [4,6]^{2}\\
          &= 23,2 - [4,6]^{2} = 2,04.
 \end{align*}
 Com isso, o desvio padrão é 
   \[
     DP(X) = \sqrt[]{Var(X)} = \sqrt[]{2,04}\approx 1,42\text{min.}
   \]

 b) Encontre Var(2X) e DP(2X), sabendo que \(\mathbb{E}(X) = 4,6.\)

 Segue que \(Var(2X) = 2^{2}Var(X) = 4Var(X) = 4 \cdot 2,04 = 8,16\) e que \(DP(2X) = \sqrt[]{Var(2X)} = 2\sqrt[]{Var(X)}\approx 2,84.\)
\end{example}
\begin{example}
 A demanda diária de um supermercado (em centenas de quilos) pode ser descrita pela variável aleatória X com função densidade 
  \[
    f(x) = \left\{\begin{array}{ll}
        \frac{2x}{3},\quad 0\leq x <1,\\
        \frac{-x}{3} + 1,\quad 1\leq x <3\\
        0,\quad \text{caso contrário}.
      \end{array}\right.
  \]
Calcule Var(X) e DP(X), sabendo que \(\mathbb{E}(X)\approx 1,3333.\)

Temos \(Var(X) = \mathbb{E}(X^{2}) - [\mathbb{E}(X)]^{2}\), ou seja, 
\begin{align*}
  Var(X) &= \int_{-\infty}^{\infty}x^{2}f(x)dx - [\mathbb{E}(X)]^{2}\\
         &= \int_{0}^{1}x^{2}f(x)dx + \int_{1}^{3}x^{2}f(x)dx\\
         &= \int_{0}^{1}\frac{2}{3}x^{3}dx + \int_{1}^{3}x^{2}\biggl(-\frac{x}{3}+1\biggr)dx - [\mathbb{E}(X)]^{2}\\
         &= \frac{x^{4}}{6}\biggl|_{0}^{1}\biggr. + \biggl[\frac{x^{3}}{3}-\frac{x^{4}}{12}\biggr]\biggl|_{1}^{3}\biggr. - [\mathbb{E}(X)]^{2}\\
         &= \frac{2}{12} + 9 - \frac{81}{12} - \frac{1}{3} + \frac{1}{12} - [1,3333]^{2}\approx 0,38
\end{align*}
Além disso, o desvio padrão vale \(DP(X) = \sqrt[]{0,38}\approx 0,62.\)
\end{example}
\begin{example}
 Suponha a variável aleatória X tal que 
   \[
     \mathbb{P}(X=1) = p\quad\text{e}\quad \mathbb{P}(X=0) = 1-p,\quad p\in [0, 1].
   \]
Como podemos interpretar \(\mathbb{E}(X)\) e Var(X)?

Sendo essa variável aleatória categórica, segue que, para p = 0,8,
  \[
    \mathbb{E}(X) = \sum\limits_{x=0}^{1}x \mathbb{P}(X=x) = 0 \cdot 0,2 + 1 \cdot 0,8 = 0,8 = p
  \]
e a variância será 
  \[
    \mathbb{E}((X-\mathbb{E}(X))^{2}) = \sum\limits_{x=0}^{1}(x-p)^{2}\mathbb{P}(X=x) = p^{2}\cdot 1 + (1-p)^{2}p = p - p^{2} = p(1-p).
  \]
que é um modelo cuja variância é máxima quando p vale \(\frac{1}{2}\).
\end{example}
\newpage

\section{Aula 09 - 31/10/2023}
\subsection{Motivações}
\begin{itemize}
  \item Desigualdade de Tchebycheff;
  \item Momentos de Ordem Superior.
\end{itemize}
\subsection{Desigualdade de Thebycheff}
  O conhecimento da função de probabilidade de uma variável aleatória possibilita-nos calcular a esperança e a variância
dela, desde que elas existam. No entanto, não somos capazes de fazer o oposto - ou seja, conhecer \(\mathbb{E}(X)\)
e Var(X) não permite-nos reconstruir a função densidade nem a função de probabilidade de X.
Embora isso seja impossível, o que podemos fazer é estabelecer limites superiores e inferiores muito úteis para estimá-las.
Uma dessas formas está contida no que é conhecido como Desigualdade de Tchebycheff.

  A desigualdade de Tchebycheff é a seguinte: 
\begin{theorem*}
  Suponha que X é uma variável aleatória
com esperança \(\mathbb{E}(X) = \mu\) e seja c um número real qualquer. Então, se \(\mathbb{E}((X-c)^{2})\)
for finita e \(\varepsilon >0\) for um número positivo qualquer, teremos 
  \[
    \mathbb{P}(|X-c|\geq \varepsilon )\leq \frac{1}{\varepsilon ^{2}}\mathbb{E}((X-c)^{2}).
  \]
\end{theorem*}
\begin{proof*}
Começamos analisando a primeira parte da expressão. Temos
\begin{align*}
  \mathbb{P}(|X-c|\geq \varepsilon )& = 1 - \mathbb{P}(|X-c| < \varepsilon )\\
                                    & = 1 - \mathbb{P}(-\varepsilon + c < X < \varepsilon + c)\\
                                    & = 1 - \int_{c-\varepsilon }^{c+\varepsilon }f(x)dx\geq 1 - \int_{-\infty}^{\infty}f(x)dx.
\end{align*}
  Note que  
  \[
    \mathbb{P}(|X-c|\geq \varepsilon ) = \int_{-\infty}^{c-\varepsilon }f(x)dx + \int_{c+\varepsilon }^{\infty}f(x)dx\leq \int_{-\infty}^{c-\varepsilon }f(x)dx + \int_{c+\varepsilon }^{\infty}\frac{(X-c)^{2}}{\varepsilon ^{2}}f(x)dx
  \]
  O mesmo vale para a integral imprópria de \(-\infty\) a \(c-\varepsilon \), pois elevamos \(-\varepsilon \) ao quadrado e chegamos no seguinte:
 \begin{align*}
   \mathbb{P}(|X-c|\geq \varepsilon )&\leq \int_{-\infty}^{c-\varepsilon }\frac{(X-c)^{2}}{\varepsilon ^{2}}f(x)dx + \int_{c+\varepsilon }^{\infty}\frac{(X-c)^{2}}{\varepsilon ^{2}}f(x)dx\\
                                     &\leq \int_{-\infty}^{\infty}\frac{(X-c)^{2}}{\varepsilon ^{2}}f(x)dx = \frac{1}{\varepsilon ^{2}}\int_{-\infty}^{\infty}(X-c)^{2}f(x)dx\\
                                     &= \frac{1}{\varepsilon ^{2}}\mathbb{E}[(X-c)^{2}].
 \end{align*}
 Portanto, obtemos a desigualdade desejada. \qedsymbol
\end{proof*}
  Há algumas formas equivalentes de interpretarmos isso. 
Considerando o evento complementar, temos 
  \[
    \mathbb{P}(|X-c|< \varepsilon )\geq 1 - \frac{1}{\varepsilon ^{2}}\mathbb{E}((X-c)^{2})
  \]
Se \(c = \mu,\) temos 
  \[
    \mathbb{P}(|X-\mu|\geq \varepsilon )\leq \frac{Var(X)}{\varepsilon ^{2}}.
  \]
Se \(c=\mu\) e \(\varepsilon = k\sigma \), em que \(\sigma ^{2}=Var(X) > 0\), obtemos 
  \[
    \mathbb{P}(|X-\mu|\geq k\sigma )\leq k^{-2}.
  \]

  Uma das coisas importantes que são notáveis é que ele \textbf{não depende do modelo de probabilidade}. Em momento algum colocamos
alguma hipótese sobre \(\mathbb{P}(\cdot )\)! Afinal, caso o modelo fosse conhecido, valeria mais a pena simplesmente fazer a conta
\begin{example}
  Considere a terceira forma equivalente da desigualdade de Tchebycheff, isto é, 
  \[
    \mathbb{P}(|X-\mu|\geq k\sigma )\leq k^{-2}.
  \]
Para \(k=\frac{3}{2},\) o que podemos dizer sobre X? E se soubermos que X é uniformemente
distribuída em \(\biggl(1-\frac{1}{\sqrt[]{3}}, 1 + \frac{1}{\sqrt[]{3}}\biggr)\)?

  Para a primeira parte, segue que 
  \[
    \mathbb{P}(|X-\mu|\geq 1,5\sigma )\leq \frac{4}{9}.
  \] 
Quanto à segunda, dado que X é uma variável aleatória distribuída uniformemente em \(\biggl(1-\frac{1}{\sqrt[]{3}}, 1 + \frac{1}{\sqrt[]{3}}\biggr)\),
sabemos descrever a densidade de probabilidade dela como 
  \[
    f(X) = \frac{1}{1+\frac{1}{\sqrt[]{3}} - 1 + \frac{1}{\sqrt[]{3}}} = \frac{\sqrt[]{3}}{2}.
  \]
  Com isso, somos capazes de calcular a esperança de X 
  \[
    \mathbb{E}(X) = \int_{1-\frac{1}{\sqrt[]{3}}}^{1 + \frac{1}{\sqrt[]{3}}} \frac{\sqrt[]{3}}{2}xdx = \frac{\sqrt[]{3}}{2}\frac{x^{2}}{2}\biggl|_{1-\frac{1}{\sqrt[]{3}}}^{1+\frac{1}{\sqrt[]{3}}}\biggr. = \frac{\sqrt[]{3}}{4} \frac{4}{\sqrt[]{3}} = 1.
  \]
  Além disso, 
  \[
    \mathbb{E}(X^{2}) + \int_{1-\frac{1}{\sqrt[]{3}}}^{1 + \frac{1}{\sqrt[]{3}}} \frac{\sqrt[]{3}}{2}x^{2}dx = \frac{\sqrt[]{3}}{2}\frac{x^{3}}{3}\biggl|_{1-\frac{1}{\sqrt[]{3}}}^{1+\frac{1}{\sqrt[]{3}}}\biggr. = \frac{\sqrt[]{3}}{6}3,8 (????)
  \]
  Depois da confusão em aula, foi mostrada que a resposta é
 \begin{align*}
   \mathbb{P}\biggl(|X-1|\geq \frac{3}{2}\sqrt[]{\frac{1}{9}}\biggr) &= \mathbb{P}\biggl(|X-1|\geq \frac{1}{2}\biggr) \\
                                                                     &= 1 - \frac{\sqrt[]{3}}{2} \approx 0,134.
 \end{align*}

\end{example}
\subsection{Momentos de Ordem Superior}
  Podemos introduzir uma noção mais geral sobre as questões até o momento vistas introduzindo outros ``momentos'' - informações importantes que usamos 
para caracterizar distribuições de probabilidade. Já vimos alguns deles - o primeiro momento é a esperança, o segundo é a dispersão e o terceiro, ainda não
visto, fornece um coeficiente de assimetria da distribuição e o quarto diz respeito ao ``achatamento'' dela.
  \begin{def*}
  Se X é uma variável aleatória discreta, com função de probabilidade \(p(x_{i}) = \mathbb{P}(X = x_{i}),\) então o \textbf{momento de ordem k}
é definido como 
  \[
    \mu_{k} = \mathbb{E}(X^{k}),
  \]
  em que 
  \[
    \mathbb{E}(X^{k}) = \sum\limits_{i=1}^{\infty}x_{i}^{k}p(x_{i}).
  \]
  Caso X seja uma variável aleatória contínua, a definição segue a mesma, mas 
  \[
    \mathbb{E}(X^{k}) = \int_{-\infty}^{\infty}X^{k}f(x)dx.\quad\square
  \]
  \end{def*}
  Além dessa noção, podemos introduzir o momento central de ordem k como
 \begin{def*}
   Se X for uma variável aleatória, com esperança finita, então o \textbf{momento central de ordem k} é definido como 
   \[
     \mu_{k}^{*} = \mathbb{E}\biggl([X-\mathbb{E}(X)]^{k}\biggr).\quad\square
   \]
 \end{def*}
 Para evitar a expansão de altas ordens na integral, definimos a seguinte função:
\begin{def*}
  A \textbf{função geradora de momentos} da variável aleatória X é definida para \(t\in \mathbb{R}\) por 
  \[
    M_{X}(t) = \mathbb{E}(e^{tX}),
  \]
  desde que a esperança seja finita para \(t\in \mathbb{R}\) em algum intervalo \(-t_{0} < t < t_{0},\) com \(t_{0} > 0.\square\)
\end{def*}
  É preciso mostrarmos que isso de fato coincide com a definição.
\newpage

\section{Aula - 09/11/2023}
\subsection{Motivações}
\begin{itemize}
  \item Função Geradora de Momentos.
\end{itemize}
\subsection{Função Geradora de Momentos (FMG)}
  Como foi visto na última aula, 
\begin{def*}
  A \textbf{função geradora de momentos} da variável aleatória X é definida para \(t\in \mathbb{R}\) por 
  \[
    M_{X}(t) = \mathbb{E}(e^{tX}),
  \]
  desde que a esperança seja finita para \(t\in \mathbb{R}\) em algum intervalo \(-t_{0} < t < t_{0},\) com \(t_{0} > 0.\square\)
\end{def*}
  A magia por trás disto está na seguinte conta: 
  Sabemos algumas coisas: a esperança é uma função linear, ou seja, podemos tirar somas e constantes pra fora dela para simplificar contas.
Isto sugere que a gente encontre uma forma de expressar \(e^{tx}\) como uma soma. Para fazer isso, lembre-se da série de Taylor em torno do 0 da exponencial:
  \[
    e^{x} = \sum\limits_{n=0}^{\infty}\frac{x^{n}}{n!}.
  \]
  Assim, 
 \begin{align*}
   \mathbb{E}(e^{tx}) &= \mathbb{E}\biggl(\sum\limits_{n=0}^{\infty}\frac{(tx)^{n}}{n!}\biggr)\\
                      &= \sum\limits_{n=0}^{\infty}\frac{1}{n!}\mathbb{E}[(tx)^{n}]\\
                      &= \sum\limits_{n=0}^{\infty}\frac{t^{n}}{n!}\mathbb{E}(x^{n})\\
                      &= \mathbb{E}(x^{0}) + t \mathbb{E}(x) + \frac{1}{2}t^{2} \mathbb{E}(x^{2}) + \dotsc.
 \end{align*}
  Isso dá uma sugestão de como utilizar a fórmula para encontrar o n-ésimo momento - caso sejamos capazes de zerar os termos com grau diferente de n,
teremos o n-ésimo momento. Mas como fazer isso? Vejamos alguns casos.
\begin{itemize}
  \item[t=0)] Para t = 0, \(\mathbb{E}(e^{tx}) = \mathbb{E}(e^{0}) = \mathbb{E}(1) = 1\), que é o primeiro termo da soma expandida.
  \item[t=1)] Neste caso, \(\mathbb{E}(e^{tx}) = \mathbb{E}(e^{x}) = \mathbb{E}(x^{0}) + \mathbb{E}(x) + \frac{1}{2}\mathbb{E}(x^{2}) + \dotsc\), o que não
é muito bom de se calcular. 
\end{itemize}
  No entanto, se conseguíssemos diminuir o grau do polinômio, o termo \(\mathbb{E}(x)\) ficaria livre de t, mas os outros termos não,
então poderíamos repetir o caso t = 0. Para essa diminuição, vimos que a derivada do cálculo funciona. Com isso, 
  \[
    \frac{dM_{x}(t)}{dt}\biggl|_{t=0}^{}\biggr.=\frac{d \mathbb{E}(e^{tx})}{dt} = \frac{d}{dt}\biggl(\sum\limits_{n=0}^{\infty}\frac{t^{n}}{n!}\mathbb{E}(x^{n})\biggr) = \sum\limits_{n=1}^{\infty}\frac{nt^{n-1}}{n(n-1)!}\mathbb{E}(x^{n}) = \mathbb{E}(x) + t \mathbb{E}(x^{2}) + \frac{1}{2}t^{2}\mathbb{E}(x^{3}) + \dotsc = \sum\limits_{n=0}^{\infty}\frac{t^{n}}{n!}\mathbb{E}(x^{n+1}).
  \]
  Calculando em t = 0, temos 
  \[
    \frac{dM_{x}(t)}{dt}\biggl|_{t=0}^{}\biggr. = \frac{d \mathbb{E}(e^{tx})}{dt}\biggl|_{t=0}^{}\biggr. = \mathbb{E}(x) + 0 + 0 + \dotsc = \mathbb{E}(x).
  \]
  Em outras palavras, a primeira derivada calculada em t = 0 nos dá a esperança, ou seja, a primeira derivada em 0 fornece o primeiro momento.
Uma pergunta natural é: será que isso funciona para outros momentos? E a resposta é que sim! Derivando a função geradora de momentos n-vezes fornece
para nós o n-ésimo momento da variável aleatória. O raciocínio é análogo:
  \begin{align*}
    \frac{d^{n}M_{x}(t)}{dt^{n}}\biggl|_{t=0}^{}\biggr.=\frac{d^{n}\mathbb{E}(e^{tx})}{dt^{n}}\biggl|_{t=0}^{}\biggr. &= \frac{d^{n}}{dt^{n}}\biggl(\sum\limits_{n=0}^{\infty}\frac{t^{n}}{n!}\mathbb{E}(x^{n})\biggr)\biggl|_{t=0}^{}\biggr. \\
                                                                                                                      &= \underbrace{0 + 0 + \dotsc + 0}_{\text{termos de grau menor que n anulam-se}} + \mathbb{E}(x^{n}) + t \mathbb{E}(x^{n+1}) + \frac{1}{2}\mathbb{E}(x^{n+2}) + \dotsc \biggl|_{t=0}^{}\biggr.\\
                                                                                                                      &= 0 + 0 + \dotsc + 0 + \mathbb{E}(x^{n}) + 0 + 0 + \dotsc\\
                                                                                                                      &= \mathbb{E}(x^{n}).
  \end{align*}
  Vejamos alguns exemplos.
\begin{example}
  Considere uma variável aleatória X uniformemente distribuída em um intervalo \([a, b]\). Qual é a esperança dessa variável aleatória ao longo do intervalo?

  Inicialmente, perceba que 
 \begin{align*}
   M_{X}(t) = \mathbb{E}(e^{tX}) &= \int_{a}^{b}e^{tX}\frac{1}{b-a}dX\\
                                 &= \frac{1}{b-a}\int_{a}^{b}e^{tx}dx\\
                                 &= \frac{1}{b-a}\frac{e^{tX}}{t}\biggl|_{a}^{b}\biggr.\\
                                 &= \frac{1}{t(b-a)}(e^{tb}-e^{ta}).
 \end{align*}
  Agora, pelo resultado obtido acima, basta derivarmos essa expressão e calculá-la em t = 0. Com efeito, 
  \[
    M_{X}'(t)\biggl|_{t=0}^{}\biggr. = \lim_{t\to 0}\biggl(\frac{(b e^{tb}-a e^{ta})t(b-a) - (b-a)(e^{tb}-e^{ta})}{t^{2}(b-a)^{2}}\biggr)  
  \]
  Pela regra de L'Hôpital,
  \[
    M_{X}'(t) = \lim_{t\to 0}\biggl(\frac{be^{tb} - ae^{ta} + (b^{2}e^{tb} - a ^{2}e^{ta})t - (be^{tb}-ae^{ta})}{2t(b-a)}\biggr) = \lim_{t\to 0}\biggl(\frac{(b-a)(b+a)}{2(b-a)}\biggr) = \frac{b+a}{2}.
  \]
\end{example}

\end{document}
